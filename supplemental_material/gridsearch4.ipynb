{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "# from time import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import math\n",
    "from scipy import stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile, SelectFromModel, f_classif, mutual_info_classif, chi2,\\\n",
    "                                        SelectFpr, SelectFdr, RFECV\n",
    "from sklearn.decomposition import FastICA, IncrementalPCA, KernelPCA, PCA, TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "### My imports\n",
    "sys.path.append('tools/')\n",
    "from dos2unix import crlf_to_lf # Borrowed and modified from multiple sources.\n",
    "from train_test import run_skl, get_base_perfs, search_em_all\n",
    "from feature_engineering import set_all_ratios, quant_flag_all, out_flag_all, flag_signs, add_k_means_n\n",
    "\n",
    "### Udacity imports (may be modified)\n",
    "# from feature_format import featureFormat, targetFeatureSplit\n",
    "# from tester import dump_classifier_and_data\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/final_project_dataset.pkl saved as data/final_project_dataset_unix.pkl in 6705 bytes.\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "### Load the dictionary containing the dataset, and clean it up.\n",
    "### Make the dict a dataframe because they're easier to work with.\n",
    "data_df = None #pd.DataFrame()\n",
    "fp = crlf_to_lf(f_in_path='data/final_project_dataset.pkl')\n",
    "with open(fp, 'rb') as data_file:\n",
    "    data_df = pd.DataFrame(pickle.load(data_file)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "### Task 1: Clean up and select what features and subsets *not* to use.\n",
    "### (Further feature selection will happen after feature engineering.)\n",
    "    \n",
    "### Drop email_address since it's a signature.\n",
    "data_df.drop(columns='email_address', inplace=True)\n",
    "### Drop the TOTAL row.\n",
    "data_df.drop(labels=['TOTAL', 'THE TRAVEL AGENCY IN THE PARK'], inplace=True)\n",
    "\n",
    "### Handle missing values here.\n",
    "### Replacing 'NaN' with None had a weird result in which values from some\n",
    "### rows were copied into the missing values of neighboring rows. No idea why.\n",
    "### Using np.nan did not have that result as far as I can tell.\n",
    "### But it is a float missing value and thus casts the column as float,\n",
    "### or as object when other values are not floats.\n",
    "data_df.replace(to_replace='NaN', value=np.nan, inplace=True)\n",
    "\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\"\n",
    "###    (if using featureFormat(), which I don't).\n",
    "\n",
    "### All units are in USD.\n",
    "fin_features = ['salary', 'bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments',\n",
    "                'loan_advances', 'other', 'expenses', 'director_fees', 'total_payments',\n",
    "                'exercised_stock_options', 'restricted_stock', 'restricted_stock_deferred', 'total_stock_value']\n",
    "pay_features = fin_features[:10]\n",
    "stock_features = fin_features[10:]\n",
    "    \n",
    "### Units are number of emails messages;\n",
    "email_features = ['to_messages', 'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi',\n",
    "                  'shared_receipt_with_poi']\n",
    "\n",
    "### Boolean, represented as integer.\n",
    "POI_label = ['poi']\n",
    "\n",
    "### The first feature must be \"poi\" if using featureFormat().\n",
    "features_list = POI_label + fin_features + email_features\n",
    "\n",
    "### Imputation recasts as float, but as object if left as bool, so set it to int for now.\n",
    "data_df['poi'] = data_df['poi'].astype(dtype=int)\n",
    "\n",
    "### Belfer's financial data is shifted one column to the right.\n",
    "### Shift it one to the left, financial data only.\n",
    "### Make total_stock_value np.nan for consistency until imputation, but could be 0.\n",
    "### May remove this row for so many NaNs, but fix it now anyway.\n",
    "data_df.loc[data_df.index == 'BELFER ROBERT', fin_features] \\\n",
    "    = data_df.loc[data_df.index == 'BELFER ROBERT', fin_features].shift(periods=-1, axis='columns',\n",
    "                                                                        fill_value=np.nan)\n",
    "\n",
    "### Bhatnagar's financial data is shifted one to the left.\n",
    "### Shift it one to the right, financial data only.\n",
    "### Make salary np.nan.\n",
    "data_df.loc[data_df.index == 'BHATNAGAR SANJAY', fin_features] \\\n",
    "    = data_df.loc[data_df.index == 'BHATNAGAR SANJAY', fin_features].shift(periods=1, axis='columns',\n",
    "                                                                           fill_value=np.nan)\n",
    "\n",
    "### Set totals to sum of values where any values are not NaN.\n",
    "### i.e. don't make 0 totals NaN, even though some NaN values may be included.\n",
    "### Makes these rows consistent with other rows that include NaNs and numbers yet have a nonNaN total.\n",
    "data_df.loc[~(data_df[pay_features].isna().all(axis='columns')), 'total_payments'] \\\n",
    "    = data_df[pay_features[:-1]].sum(axis='columns')\n",
    "data_df.loc[~(data_df[stock_features].isna().all(axis='columns')), 'total_stock_value'] \\\n",
    "    = data_df[stock_features[:-1]].sum(axis='columns')\n",
    "\n",
    "### Add one to Glisan's to_message to at least equal shared_receipt_with_poi.\n",
    "data_df.loc['GLISAN JR BEN F', 'to_messages'] = 874\n",
    "\n",
    "### Drop features that are too sparse.\n",
    "drop_feats_lst = ['loan_advances']\n",
    "data_df.drop(columns=drop_feats_lst, inplace=True)\n",
    "fin_features = [feat for feat in fin_features if feat not in drop_feats_lst]\n",
    "pay_features = [feat for feat in pay_features if feat not in drop_feats_lst]\n",
    "stock_features = [feat for feat in stock_features if feat not in drop_feats_lst]\n",
    "email_features = [feat for feat in email_features if feat not in drop_feats_lst]\n",
    "features_list = [feat for feat in features_list if feat not in drop_feats_lst]\n",
    "\n",
    "### Removed 'email' as signature upon loading.\n",
    "\n",
    "### Drop persons who have NaN payment totals or NaN stock totals or NaN to_messages or NaN from_messages,\n",
    "### and are missing 70% of their values.\n",
    "### (Already made sure that all totals are not NaN if they have subvalues.)\n",
    "nan_limit = 0.7 * len(data_df.columns)\n",
    "sparse_records_idx_arr = \\\n",
    "    data_df.loc[data_df['total_payments'].isna() \\\n",
    "                | data_df['total_stock_value'].isna() \\\n",
    "                | data_df['to_messages'].isna() \\\n",
    "                | data_df['from_messages'].isna()]\\\n",
    "           .loc[data_df.isna().sum(axis='columns') > nan_limit]\\\n",
    "           .index.values\n",
    "data_df.drop(labels=sparse_records_idx_arr, inplace=True)\n",
    "\n",
    "### This leaves 123 records over 19 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline model performance metrics:\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Training time: 0.003 s\n",
      "Prediction time: 0.002 s\n",
      "Confusion matrix:\n",
      " [[20  3]\n",
      " [ 2  1]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.90909091, 0.25      ]), array([0.86956522, 0.33333333]), array([0.88888889, 0.28571429]), array([23,  3], dtype=int64))\n",
      "RandomForestClassifier()\n",
      "Training time: 0.194 s\n",
      "Prediction time: 0.013 s\n",
      "Confusion matrix:\n",
      " [[21  2]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.875, 0.   ]), array([0.91304348, 0.        ]), array([0.89361702, 0.        ]), array([23,  3], dtype=int64))\n",
      "AdaBoostClassifier()\n",
      "Training time: 0.084 s\n",
      "Prediction time: 0.011 s\n",
      "Confusion matrix:\n",
      " [[21  2]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.875, 0.   ]), array([0.91304348, 0.        ]), array([0.89361702, 0.        ]), array([23,  3], dtype=int64))\n",
      "KNeighborsClassifier()\n",
      "Training time: 0.002 s\n",
      "Prediction time: 0.004 s\n",
      "Confusion matrix:\n",
      " [[22  1]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.88, 0.  ]), array([0.95652174, 0.        ]), array([0.91666667, 0.        ]), array([23,  3], dtype=int64))\n",
      "GaussianNB()\n",
      "Training time: 0.003 s\n",
      "Prediction time: 0.002 s\n",
      "Confusion matrix:\n",
      " [[ 6 17]\n",
      " [ 2  1]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.75      , 0.05555556]), array([0.26086957, 0.33333333]), array([0.38709677, 0.0952381 ]), array([23,  3], dtype=int64))\n",
      "SVC()\n",
      "Training time: 0.003 s\n",
      "Prediction time: 0.002 s\n",
      "Confusion matrix:\n",
      " [[22  1]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.88, 0.  ]), array([0.95652174, 0.        ]), array([0.91666667, 0.        ]), array([23,  3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "### Make a quick baseline model for comparison.\n",
    "### Impute with 0.\n",
    "imp_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0, copy=False)\n",
    "imp_0 = imp_0.fit(X=data_df)\n",
    "data_imp0_df = pd.DataFrame(data=imp_0.transform(X=data_df), columns=data_df.columns, index=data_df.index)\n",
    "\n",
    "### Split now for baseline model, but also before further processing, outlier removal, scaling, engineering,\n",
    "### or else test set info leaks into training set.\n",
    "### Even imputation could if using multivariate imputation or median.\n",
    "### Decision on how to treat the data should not be influenced by test set either.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_imp0_df[features_list[1:]], data_imp0_df[['poi']],\n",
    "                                                    test_size=.3, random_state=42)\n",
    "### Some algorithms want 1D y data.\n",
    "y_train_1d = np.ravel(y_train.astype(bool))\n",
    "y_test_1d = np.ravel(y_test.astype(bool))\n",
    "\n",
    "### Split train set again for a baseline model that won't touch the final test set.\n",
    "X_train_base, X_test_base, y_train_base, y_test_base \\\n",
    "    = train_test_split(X_train, y_train, test_size=.3, random_state=42)\n",
    "y_train_1d_base = np.ravel(y_train_base.astype(bool))\n",
    "y_test_1d_base = np.ravel(y_test_base.astype(bool))\n",
    "\n",
    "### For metrics.\n",
    "ordered_cols_lst = ['nonPOI_prec', 'POI_prec', 'nonPOI_rec', 'POI_rec', 'nonPOI_f', 'POI_f', 'nonPOI_sup',\n",
    "                    'POI_sup', 't_neg', 'f_neg', 'f_pos', 't_pos', 'train_t', 'predict_t', 'model']\n",
    "base_perf_df = pd.DataFrame(columns=ordered_cols_lst)\n",
    "\n",
    "clf_dict = {'dt_clf': DecisionTreeClassifier, 'rf_clf': RandomForestClassifier, 'ab_clf': AdaBoostClassifier,\n",
    "            'kn_clf': KNeighborsClassifier, 'gnb_clf': GaussianNB, 'svc_clf': svm.SVC}\n",
    "\n",
    "print('\\nBaseline model performance metrics:\\n')\n",
    "for key, method in clf_dict.items():\n",
    "    _, _, _, _, perf_sr = run_skl(method=method, X_train=X_train_base,\n",
    "                                  y_train=y_train_1d_base,\n",
    "                                  X_test=X_test_base,\n",
    "                                  y_test=y_test_1d_base,\n",
    "                                  perf_series=key)\n",
    "    base_perf_df = base_perf_df.append(perf_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "### Task 2: Remove/handle outliers\n",
    "\n",
    "### Dropped ['TOTAL', 'THE TRAVEL AGENCY IN THE PARK'] row upon loading.\n",
    "\n",
    "### Drop features that are too sparse.\n",
    "### Drop 'other' because it's ill-defined and seems overly represented within important features. The nebulous nature of it seems like a good fit for fraud, but high gross 'other' amounts are more correlated with nonPOIs than POIs if anything.\n",
    "drop_feats_lst = ['director_fees', 'restricted_stock_deferred', 'other']\n",
    "\n",
    "X_train.drop(columns=drop_feats_lst, inplace=True)\n",
    "X_test.drop(columns=drop_feats_lst, inplace=True)\n",
    "data_df.drop(columns=drop_feats_lst, inplace=True)\n",
    "\n",
    "fin_features = [feat for feat in fin_features if feat not in drop_feats_lst]\n",
    "pay_features = [feat for feat in pay_features if feat not in drop_feats_lst]\n",
    "stock_features = [feat for feat in stock_features if feat not in drop_feats_lst]\n",
    "email_features = [feat for feat in email_features if feat not in drop_feats_lst]\n",
    "features_list = [feat for feat in features_list if feat not in drop_feats_lst]\n",
    "del drop_feats_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Don't drop records now because it will mess up the split for Udacity.\n",
    "### Could drop earlier and resplit, but I've already done a lot of EDA behind the scenes.\n",
    "### NaN his financials.\n",
    "X_train.loc[['POWERS WILLIAM'], pay_features] = np.nan\n",
    "data_df.loc[['POWERS WILLIAM'], pay_features] = np.nan\n",
    "\n",
    "### Bivariate linear regression of the ratios between to/from/shared with POIs and\n",
    "### total to and from messages revealed that top coding to_messages and from_messages\n",
    "### may slightly aid nonPOI precision.\n",
    "### Only top coding the training set in order to bias the model,\n",
    "### since I am less concerned with accuracy than I am with POI recall,\n",
    "### and by extension, nonPOI precision.\n",
    "X_train['to_messages'] = X_train['to_messages'].apply(lambda x: x if x < 12000 or np.isnan(x) else 12000)\n",
    "X_train['from_messages'] = X_train['from_messages'].apply(lambda x: x if x < 8000 or np.isnan(x) else 8000)\n",
    "data_df.loc[X_train.index]['to_messages'] \\\n",
    "    = data_df.loc[X_train.index]['to_messages'].apply(lambda x: x if x < 12000 or np.isnan(x) else 12000)\n",
    "data_df.loc[X_train.index]['from_messages'] \\\n",
    "    = data_df.loc[X_train.index]['from_messages'].apply(lambda x: x if x < 8000 or np.isnan(x) else 8000)\n",
    "\n",
    "### Not sure whether top coding these will really help or hinder, if anything at all.\n",
    "### But, it appears to potentially aid POI recall in some cases\n",
    "### when comparing payments to totals, and it's more in line with best practices.\n",
    "### Only really affects Frevert.\n",
    "top = X_train['total_payments'].dropna().sort_values()[-2]\n",
    "X_train['total_payments'] = X_train['total_payments'].apply(lambda x : x if x < top or np.isnan(x) else top)\n",
    "data_df.loc[X_train.index]['total_payments'] \\\n",
    "    = data_df.loc[X_train.index]['total_payments'].apply(lambda x : x if x < top or np.isnan(x) else top)\n",
    "\n",
    "top = X_train['long_term_incentive'].dropna().sort_values()[-2]\n",
    "X_train['long_term_incentive'] = \\\n",
    "    X_train['long_term_incentive'].apply(lambda x : x if x < top or np.isnan(x) else top)\n",
    "data_df.loc[X_train.index]['long_term_incentive'] \\\n",
    "    = data_df.loc[X_train.index]['long_term_incentive'].apply(lambda x : x if x < top or np.isnan(x) else top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same story as Powers, NaN all of Belfer instead of simply dropping.\n",
    "X_train.loc['BELFER ROBERT'] = np.nan\n",
    "# belfers_poi = data_df.loc['BELFER ROBERT']['poi']\n",
    "data_df.loc['BELFER ROBERT', features_list[1:]]= np.nan\n",
    "# data_df.loc['BELFER ROBERT']['poi'] = belfers_poi\n",
    "\n",
    "### After look at distributions of ratios of features, more top/bottom coding. ###\n",
    "\n",
    "### Nan Bannantine's salary, and bottom code salary.\n",
    "X_train.loc['BANNANTINE JAMES M', 'salary'] = np.nan\n",
    "data_df.loc['BANNANTINE JAMES M', 'salary'] = np.nan\n",
    "bottom = X_train['salary'].dropna().sort_values(ascending=False)[-2]\n",
    "X_train['salary'] = X_train['salary'].apply(lambda x : x if x > bottom or np.isnan(x) else bottom)\n",
    "data_df.loc[X_train.index]['salary'] \\\n",
    "    = data_df.loc[X_train.index]['salary'].apply(lambda x : x if x > bottom or np.isnan(x) else bottom)\n",
    "\n",
    "### These two only have one, very low payment value.\n",
    "X_train.loc[['HAYES ROBERT E', 'HAUG DAVID L'], pay_features] = np.nan\n",
    "data_df.loc[['HAYES ROBERT E', 'HAUG DAVID L'], pay_features] = np.nan\n",
    "\n",
    "### Top code deferred_income.\n",
    "top = X_train['deferred_income'].dropna().sort_values(ascending=True)[-3]\n",
    "X_train['deferred_income'] = X_train['deferred_income'].apply(lambda x : x if x < top or np.isnan(x) else top)\n",
    "data_df.loc[X_train.index]['deferred_income'] = \\\n",
    "    data_df.loc[X_train.index]['deferred_income'].apply(lambda x : x if x < top or np.isnan(x) else top)\n",
    "del top\n",
    "del bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "### Task 3: Create new feature(s)\n",
    "\n",
    "\n",
    "### Start with all ratios, within respective subspaces (fin:fin, e:e).\n",
    "### Add financial ratios within subspaces to data sets.\n",
    "pay_feats_divby_df = set_all_ratios(df=X_train, denoms=pay_features, numers=pay_features)\n",
    "stock_feats_divby_df = set_all_ratios(df=X_train, denoms=stock_features, numers=stock_features)\n",
    "\n",
    "### Only plausible email ratios (all reciprocals still, to get the 0s to infs):\n",
    "to_lst = ['to_messages', 'from_poi_to_this_person', 'shared_receipt_with_poi']\n",
    "from_lst = ['from_messages', 'from_this_person_to_poi']\n",
    "email_to_divby_df = set_all_ratios(df=X_train, denoms=to_lst, numers=to_lst)\n",
    "email_from_divby_df = set_all_ratios(df=X_train, denoms=from_lst, numers=from_lst)\n",
    "\n",
    "X_train = pd.concat(objs=[X_train, pay_feats_divby_df, stock_feats_divby_df, email_to_divby_df,\n",
    "                          email_from_divby_df], axis=1)\n",
    "\n",
    "### Do for test set.\n",
    "pay_feats_divby_df = set_all_ratios(df=X_test, denoms=pay_features, numers=pay_features)\n",
    "stock_feats_divby_df = set_all_ratios(df=X_test, denoms=stock_features, numers=stock_features)\n",
    "email_to_divby_df = set_all_ratios(df=X_test, denoms=to_lst, numers=to_lst)\n",
    "email_from_divby_df = set_all_ratios(df=X_test, denoms=from_lst, numers=from_lst)\n",
    "X_test = pd.concat(objs=[X_test, pay_feats_divby_df, stock_feats_divby_df, email_to_divby_df,\n",
    "                         email_from_divby_df], axis=1)\n",
    "\n",
    "### Do for full set.\n",
    "pay_feats_divby_df = set_all_ratios(df=data_df, denoms=pay_features, numers=pay_features)\n",
    "stock_feats_divby_df = set_all_ratios(df=data_df, denoms=stock_features, numers=stock_features)\n",
    "email_to_divby_df = set_all_ratios(df=data_df, denoms=to_lst, numers=to_lst)\n",
    "email_from_divby_df = set_all_ratios(df=data_df, denoms=from_lst, numers=from_lst)\n",
    "data_df = pd.concat(objs=[data_df, pay_feats_divby_df, stock_feats_divby_df, email_to_divby_df,\n",
    "                          email_from_divby_df], axis=1)\n",
    "del to_lst\n",
    "del from_lst\n",
    "\n",
    "### Set all np.inf to np.nan.\n",
    "X_train = X_train.apply(func=(lambda col: col.apply(func=(lambda x: np.nan if abs(x) == abs(np.inf) else x))))\n",
    "X_test = X_test.apply(func=(lambda col: col.apply(func=(lambda x: np.nan if abs(x) == abs(np.inf) else x))))\n",
    "data_df = data_df.apply(func=(lambda col: col.apply(func=(lambda x: np.nan if abs(x) == abs(np.inf) else x))))\n",
    "\n",
    "### Remove all features containing less than 30% training observations.\n",
    "drop_lst = list(X_train.count().loc[X_train.count() < .3 * len(X_train.index)].index)\n",
    "X_train.drop(columns=drop_lst, inplace=True)\n",
    "X_test.drop(columns=drop_lst, inplace=True)\n",
    "data_df.drop(columns=drop_lst, inplace=True)\n",
    "\n",
    "pay_feats_divby_lst = [feat for feat in list(pay_feats_divby_df.columns) if not feat in drop_lst]\n",
    "stock_feats_divby_lst = [feat for feat in list(stock_feats_divby_df.columns) if not feat in drop_lst]\n",
    "email_feats_divby_lst = [feat for feat in list(email_to_divby_df.columns) if not feat in drop_lst] \\\n",
    "                        + [feat for feat in list(email_from_divby_df.columns) if not feat in drop_lst]\n",
    "fin_features = [feat for feat in fin_features if feat not in drop_lst] + pay_feats_divby_lst \\\n",
    "    + stock_feats_divby_lst\n",
    "pay_features = [feat for feat in pay_features if feat not in drop_lst]\n",
    "stock_features = [feat for feat in stock_features if feat not in drop_lst]\n",
    "email_features = [feat for feat in email_features if feat not in drop_lst] + email_feats_divby_lst\n",
    "features_list = [feat for feat in features_list if feat not in drop_lst] + pay_feats_divby_lst \\\n",
    "    + stock_feats_divby_lst + email_feats_divby_lst\n",
    "del drop_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create features that flag mambership in various quantiles, outliership, and x > 0.\n",
    "### Use multiple quantiles: quartiles, quintiles, and deciles.\n",
    "### Retain np.nans.\n",
    "\n",
    "to_flag_lst = fin_features + email_features\n",
    "\n",
    "### Could write a function, but I'll just paste and edit.\n",
    "### Flag train set.\n",
    "fin_quant_flags_df = quant_flag_all(df=X_train[fin_features], quant_df=X_train[fin_features])\n",
    "email_quant_flags_df = quant_flag_all(df=X_train[email_features], quant_df=X_train[email_features])\n",
    "fin_out_flags_df = out_flag_all(df=X_train[fin_features], quant_df=X_train[fin_features])\n",
    "email_out_flags_df = out_flag_all(df=X_train[email_features], quant_df=X_train[email_features])\n",
    "sign_flags_df = flag_signs(df=X_train[to_flag_lst])\n",
    "X_train = pd.concat(objs=[X_train, fin_quant_flags_df, email_quant_flags_df, fin_out_flags_df,\n",
    "                          email_out_flags_df, sign_flags_df], axis=1)\n",
    "\n",
    "### Flag test set.\n",
    "fin_quant_flags_df = quant_flag_all(df=X_test[fin_features], quant_df=X_train[fin_features])\n",
    "email_quant_flags_df = quant_flag_all(df=X_test[email_features], quant_df=X_train[email_features])\n",
    "fin_out_flags_df = out_flag_all(df=X_test[fin_features], quant_df=X_train[fin_features])\n",
    "email_out_flags_df = out_flag_all(df=X_test[email_features], quant_df=X_train[email_features])\n",
    "sign_flags_df = flag_signs(df=X_test[to_flag_lst])\n",
    "X_test = pd.concat(objs=[X_test, fin_quant_flags_df, email_quant_flags_df, fin_out_flags_df,\n",
    "                          email_out_flags_df, sign_flags_df], axis=1)\n",
    "\n",
    "### Flag whole set.\n",
    "fin_quant_flags_df = quant_flag_all(df=data_df[fin_features], quant_df=X_train[fin_features])\n",
    "email_quant_flags_df = quant_flag_all(df=data_df[email_features], quant_df=X_train[email_features])\n",
    "fin_out_flags_df = out_flag_all(df=data_df[fin_features], quant_df=X_train[fin_features])\n",
    "email_out_flags_df = out_flag_all(df=data_df[email_features], quant_df=X_train[email_features])\n",
    "sign_flags_df = flag_signs(df=data_df[to_flag_lst])\n",
    "data_df = pd.concat(objs=[data_df, fin_quant_flags_df, email_quant_flags_df, fin_out_flags_df,\n",
    "                          email_out_flags_df, sign_flags_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and update feature lists.\n",
    "fin_quant_flags_lst = list(fin_quant_flags_df.columns)\n",
    "email_quant_flags_lst = list(email_quant_flags_df.columns)\n",
    "quant_flags_lst = fin_quant_flags_lst + email_quant_flags_lst\n",
    "\n",
    "fin_out_flags_lst = list(fin_out_flags_df.columns)\n",
    "email_out_flags_lst = list(email_out_flags_df.columns)\n",
    "out_flags_lst = fin_out_flags_lst + email_out_flags_lst\n",
    "\n",
    "fin_features += fin_quant_flags_lst + fin_out_flags_lst\n",
    "email_features += email_quant_flags_lst + email_out_flags_lst\n",
    "\n",
    "sign_flags_lst = list(sign_flags_df.columns)\n",
    "\n",
    "features_list = features_list + quant_flags_lst + out_flags_lst + sign_flags_lst\n",
    "\n",
    "del to_flag_lst\n",
    "del fin_quant_flags_df\n",
    "del email_quant_flags_df\n",
    "del fin_out_flags_df\n",
    "del email_out_flags_df\n",
    "del sign_flags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scale features\n",
    "### Just do min-max on floats, not bools (some are objects for now because np.nan)\n",
    "\n",
    "float_feats_lst = fin_features + email_features\n",
    "bool_feats_lst =  sign_flags_lst\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_floats = pd.DataFrame(data=scaler.fit_transform(X=X_train[float_feats_lst]),\n",
    "                            columns=float_feats_lst, index=X_train.index)\n",
    "X_train_scaled = pd.concat(objs=[train_floats, X_train[bool_feats_lst]], axis=1)\n",
    "\n",
    "test_floats = pd.DataFrame(data=scaler.transform(X=X_test[float_feats_lst]),\n",
    "                           columns=float_feats_lst,index=X_test.index)\n",
    "X_test_scaled = pd.concat(objs=[test_floats, X_test[bool_feats_lst]], axis=1)\n",
    "\n",
    "all_floats = pd.DataFrame(data=scaler.transform(X=data_df[float_feats_lst]),\n",
    "                          columns=float_feats_lst, index=data_df.index)\n",
    "data_df_scaled = pd.concat(objs=[data_df['poi'], all_floats, data_df[bool_feats_lst]], axis=1)\n",
    "\n",
    "del float_feats_lst\n",
    "del scaler\n",
    "del train_floats\n",
    "del test_floats\n",
    "del all_floats\n",
    "del X_train\n",
    "del X_test\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Impute missing values:\n",
    "### Financial features to 0, email features to median, and bools to mode.\n",
    "### Restore bools to bool (from object because np.nan)\n",
    "\n",
    "imp0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "imp_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imp_mod = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "### Financial features to 0.\n",
    "fin_train_df = pd.DataFrame(data=imp0.fit_transform(X=X_train_scaled[fin_features]),\n",
    "                        columns=fin_features, index=X_train_scaled.index)\n",
    "fin_test_df = pd.DataFrame(data=imp0.transform(X=X_test_scaled[fin_features]),\n",
    "                       columns=fin_features, index=X_test_scaled.index)\n",
    "fin_all_df = pd.DataFrame(data=imp0.transform(X=data_df_scaled[fin_features]),\n",
    "                      columns=fin_features, index=data_df_scaled.index)\n",
    "\n",
    "### email features to median\n",
    "email_train_df = pd.DataFrame(data=imp_med.fit_transform(X=X_train_scaled[email_features]),\n",
    "                        columns=email_features, index=X_train_scaled.index)\n",
    "email_test_df = pd.DataFrame(data=imp_med.transform(X=X_test_scaled[email_features]),\n",
    "                       columns=email_features, index=X_test_scaled.index)\n",
    "email_all_df = pd.DataFrame(data=imp_med.transform(X=data_df_scaled[email_features]),\n",
    "                      columns=email_features, index=data_df_scaled.index)\n",
    "\n",
    "### Bools to mode.\n",
    "### Restore bools to bool (from object because np.nan)\n",
    "bool_train_df = (pd.DataFrame(data=imp_mod.fit_transform(X=X_train_scaled[bool_feats_lst]),\n",
    "                              columns=bool_feats_lst, index=X_train_scaled.index)).astype(bool)\n",
    "bool_test_df = pd.DataFrame(data=imp_mod.transform(X=X_test_scaled[bool_feats_lst]),\n",
    "                            columns=bool_feats_lst, index=X_test_scaled.index).astype(bool)\n",
    "bool_all_df = pd.DataFrame(data=imp_mod.transform(X=data_df_scaled[bool_feats_lst]),\n",
    "                           columns=bool_feats_lst, index=data_df_scaled.index).astype(bool)\n",
    "\n",
    "### Concat\n",
    "X_train_scaled_imp = pd.concat(objs=[fin_train_df, email_train_df, bool_train_df], axis=1)\n",
    "X_test_scaled_imp = pd.concat(objs=[fin_test_df, email_test_df, bool_test_df], axis=1)\n",
    "data_df_scaled_imp = pd.concat(objs=[data_df_scaled['poi'], fin_all_df, email_all_df, bool_all_df], axis=1)\n",
    "\n",
    "del fin_train_df\n",
    "del email_train_df\n",
    "del bool_train_df\n",
    "del fin_test_df\n",
    "del email_test_df\n",
    "del bool_test_df\n",
    "del fin_all_df\n",
    "del email_all_df\n",
    "del bool_all_df\n",
    "del bool_feats_lst\n",
    "del X_train_scaled\n",
    "del X_test_scaled\n",
    "del data_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sklearn predictions as features\n",
    "\n",
    "# 1) Kmeans cluster.\n",
    "train_cluster_subspace, test_cluster_subspace \\\n",
    "    = add_k_means_n(X_train=X_train_scaled_imp, X_test=X_test_scaled_imp)\n",
    "X_train_scaled_imp_k = pd.concat(objs=[X_train_scaled_imp, train_cluster_subspace], axis=1)\n",
    "X_test_scaled_imp_k = pd.concat(objs=[X_test_scaled_imp, test_cluster_subspace], axis=1)\n",
    "\n",
    "train_cluster_subspace, test_cluster_subspace \\\n",
    "    = add_k_means_n(X_train=X_train_scaled_imp, X_test=data_df_scaled_imp[features_list[1:]])\n",
    "data_df_scaled_imp_k = pd.concat(objs=[data_df_scaled_imp, test_cluster_subspace], axis=1)\n",
    "\n",
    "k_means_feats_lst = k_means_feats_lst = list(train_cluster_subspace.columns)\n",
    "features_list += k_means_feats_lst\n",
    "\n",
    "del train_cluster_subspace\n",
    "del test_cluster_subspace\n",
    "del X_train_scaled_imp\n",
    "del X_test_scaled_imp\n",
    "del data_df_scaled_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " base_perf_engineered\n",
      "\n",
      " dt_clf\n",
      "DecisionTreeClassifier()\n",
      "Training time: 0.022 s\n",
      "Prediction time: 0.006 s\n",
      "Confusion matrix:\n",
      " [[21  2]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.875, 0.   ]), array([0.91304348, 0.        ]), array([0.89361702, 0.        ]), array([23,  3], dtype=int64))\n",
      "\n",
      " rf_clf\n",
      "RandomForestClassifier()\n",
      "Training time: 0.182 s\n",
      "Prediction time: 0.017 s\n",
      "Confusion matrix:\n",
      " [[21  2]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.875, 0.   ]), array([0.91304348, 0.        ]), array([0.89361702, 0.        ]), array([23,  3], dtype=int64))\n",
      "\n",
      " ab_clf\n",
      "AdaBoostClassifier()\n",
      "Training time: 0.178 s\n",
      "Prediction time: 0.044 s\n",
      "Confusion matrix:\n",
      " [[20  3]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.86956522, 0.        ]), array([0.86956522, 0.        ]), array([0.86956522, 0.        ]), array([23,  3], dtype=int64))\n",
      "\n",
      " kn_clf\n",
      "KNeighborsClassifier()\n",
      "Training time: 0.007 s\n",
      "Prediction time: 0.008 s\n",
      "Confusion matrix:\n",
      " [[23  0]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.88461538, 0.        ]), array([1., 0.]), array([0.93877551, 0.        ]), array([23,  3], dtype=int64))\n",
      "\n",
      " gnb_clf\n",
      "GaussianNB()\n",
      "Training time: 0.008 s\n",
      "Prediction time: 0.004 s\n",
      "Confusion matrix:\n",
      " [[20  3]\n",
      " [ 1  2]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.95238095, 0.4       ]), array([0.86956522, 0.66666667]), array([0.90909091, 0.5       ]), array([23,  3], dtype=int64))\n",
      "\n",
      " svc_clf\n",
      "SVC()\n",
      "Training time: 0.016 s\n",
      "Prediction time: 0.0 s\n",
      "Confusion matrix:\n",
      " [[23  0]\n",
      " [ 3  0]]\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.88461538, 0.        ]), array([1., 0.]), array([0.93877551, 0.        ]), array([23,  3], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "### Construct baseline performance with all features before tuning/selection.\n",
    "### Split train set again for a baseline model that won't touch the final test set.\n",
    "X_train_base, X_test_base, y_train_base, y_test_base \\\n",
    "    = train_test_split(X_train_scaled_imp_k, y_train, test_size=.3, random_state=42)\n",
    "y_train_1d_base = np.ravel(y_train_base.astype(bool))\n",
    "y_test_1d_base = np.ravel(y_test_base.astype(bool))\n",
    "\n",
    "base_perf_engineered_df = pd.DataFrame(columns=ordered_cols_lst)\n",
    "\n",
    "base_perfs_dict = {'base_perf_engineered': base_perf_engineered_df}\n",
    "imp_sets_dict = {'base_perf_engineered': [X_train_base, X_test_base]}\n",
    "\n",
    "### Modifies the base_perfs_dict in place, since dict has no deep copy method.\n",
    "get_base_perfs(base_perfs_dict=base_perfs_dict, imp_sets_dict=imp_sets_dict, clf_dict=clf_dict, y_train=y_train_1d_base,\n",
    "               y_test=y_test_1d_base)\n",
    "\n",
    "base_perfs_dict['first_base'] = base_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_gscvs_dict = None\n",
    "with open('imp_gscvs_dict3.pkl', 'rb') as file:\n",
    "    imp_gscvs_dict = pickle.load(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed_impute': {'sel_per_fica_rf_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('fica', FastICA()),\n",
       "                                         ('rf_clf', RandomForestClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
       "                           'fica__fun': ['logcosh', 'exp', 'cube'],\n",
       "                           'fica__random_state': [42],\n",
       "                           'rf_clf__bootstrap': [True, False],\n",
       "                           'rf_clf__max_depth': [16, 32, 64],\n",
       "                           'rf_clf__max_featu...\n",
       "                           'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
       "                           'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3),\n",
       "  'sel_per_fica_ab_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('fica', FastICA()),\n",
       "                                         ('ab_clf', AdaBoostClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
       "                           'ab_clf__base_estimator': [DecisionTreeClassifier(random_state=42),\n",
       "                                                      RandomForestClassifier(n_jobs=-1,\n",
       "                                                                             random_state=42),\n",
       "                                                      AdaBoostClassifier(random_state=42),...\n",
       "                           'fica__algorithm': ['parallel', 'deflation'],\n",
       "                           'fica__fun': ['logcosh', 'exp', 'cube'],\n",
       "                           'fica__random_state': [42],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3),\n",
       "  'sel_per_fica_kn_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('fica', FastICA()),\n",
       "                                         ('kn_clf', KNeighborsClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
       "                           'fica__fun': ['logcosh', 'exp', 'cube'],\n",
       "                           'fica__random_state': [42],\n",
       "                           'kn_clf__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
       "                           'kn_clf__leaf_size': [4, 8, 12, 16, 2...\n",
       "                           'kn_clf__n_jobs': [-1],\n",
       "                           'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                           'kn_clf__weights': ['uniform', 'distance'],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3)}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_gscvs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sel_per_fica_rf_clf \n",
      "\n",
      "Best score:\n",
      " 0.884967320261438 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per', SelectPercentile(percentile=15)),\n",
      "                ('fica',\n",
      "                 FastICA(algorithm='deflation', fun='exp', random_state=42)),\n",
      "                ('rf_clf',\n",
      "                 RandomForestClassifier(max_depth=16, max_features='log2',\n",
      "                                        min_samples_leaf=4, n_estimators=4,\n",
      "                                        n_jobs=-1, random_state=42))],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [187 206 207 208 209 210 225 291 298 305 317 318 319 320 321 331 332 333\n",
      " 334 339 340 346 347 350 351 352] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing rf_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[28  3]\n",
      " [ 6  0]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.82352941, 0.        ]), array([0.90322581, 0.        ]), array([0.86153846, 0.        ]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.0 \n",
      "\n",
      "\n",
      "\n",
      "sel_per_fica_ab_clf \n",
      "\n",
      "Best score:\n",
      " 0.8725490196078433 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per',\n",
      "                 SelectPercentile(score_func=functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42))),\n",
      "                ('fica',\n",
      "                 FastICA(algorithm='deflation', fun='exp', random_state=42)),\n",
      "                ('ab_clf',\n",
      "                 AdaBoostClassifier(base_estimator=GaussianNB(),\n",
      "                                    n_estimators=16, random_state=42))],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   1.2s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing ab_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[31  0]\n",
      " [ 6  0]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.83783784, 0.        ]), array([1., 0.]), array([0.91176471, 0.        ]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.0 \n",
      "\n",
      "\n",
      "\n",
      "sel_per_fica_kn_clf \n",
      "\n",
      "Best score:\n",
      " 0.8843137254901962 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per',\n",
      "                 SelectPercentile(percentile=15,\n",
      "                                  score_func=functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42))),\n",
      "                ('fica', FastICA(fun='exp', random_state=42)),\n",
      "                ('kn_clf',\n",
      "                 KNeighborsClassifier(algorithm='ball_tree', leaf_size=4,\n",
      "                                      n_jobs=-1, n_neighbors=3))],\n",
      "         verbose=True) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   1.2s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.9s\n",
      "[Pipeline] ............ (step 3 of 3) Processing kn_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[31  0]\n",
      " [ 6  0]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.83783784, 0.        ]), array([1., 0.]), array([0.91176471, 0.        ]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.0 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "get_f = lambda precision, recall: 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "for name, gscv in imp_gscvs_dict['mixed_impute'].items():\n",
    "    print(name, '\\n')\n",
    "    print('Best score:\\n', gscv.best_score_, '\\n')\n",
    "    print('Best estimator:\\n', gscv.best_estimator_, '\\n')\n",
    "    clf = gscv.best_estimator_.fit(X=X_train_scaled_imp_k, y=y_train_1d)\n",
    "    pred = clf.predict(X_test_scaled_imp_k)\n",
    "    conf = confusion_matrix(y_true=y_test_1d, y_pred=pred)\n",
    "    print('Confusion matrix:\\n', conf, '\\n')\n",
    "    prf = precision_recall_fscore_support(y_true=y_test_1d, y_pred=pred)\n",
    "    print('Precision, recall, f beta score, support:\\n', prf, '\\n')\n",
    "    print('Custom F beta using nonPOI precision and POI recall:\\n', get_f(prf[0][0], prf[1][1]), '\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [187 206 207 208 209 210 225 291 298 305 317 318 319 320 321 331 332 333\n",
      " 334 339 340 346 347 350 351 352] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.2s\n",
      "[Pipeline] ............ (step 3 of 3) Processing rf_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[31  0]\n",
      " [ 6  0]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.83783784, 0.        ]), array([1., 0.]), array([0.91176471, 0.        ]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(steps=[('sel_per', SelectPercentile(percentile=15)),\n",
    "                ('fica',\n",
    "                 FastICA(algorithm='deflation', fun='exp', random_state=42)),\n",
    "                ('rf_clf',\n",
    "                 RandomForestClassifier(max_depth=16, max_features='log2',\n",
    "                                        min_samples_leaf=4, n_estimators=4,\n",
    "                                        n_jobs=-1, random_state=42))],\n",
    "               verbose=True).fit(X=X_train_scaled_imp_k, y=y_train_1d)\n",
    "pred = clf.predict(X=X_test_scaled_imp_k)\n",
    "pred = gscv.predict(X_test_scaled_imp_k)\n",
    "conf = confusion_matrix(y_true=y_test_1d, y_pred=pred)\n",
    "print('Confusion matrix:\\n', conf, '\\n')\n",
    "prf = precision_recall_fscore_support(y_true=y_test_1d, y_pred=pred)\n",
    "print('Precision, recall, f beta score, support:\\n', prf, '\\n')\n",
    "print('Custom F beta using nonPOI precision and POI recall:\\n', get_f(prf[0][0], prf[1][1]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 sel_per_empty_rf_clf \n",
      "\n",
      "Fitting 5 folds for each of 10080 candidates, totalling 50400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8176 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9232 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11536 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 15472 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 16912 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 21616 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25072 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26896 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 30736 tasks      | elapsed: 33.7min\n",
      "[Parallel(n_jobs=-1)]: Done 32752 tasks      | elapsed: 35.9min\n",
      "[Parallel(n_jobs=-1)]: Done 34832 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=-1)]: Done 36976 tasks      | elapsed: 40.5min\n",
      "[Parallel(n_jobs=-1)]: Done 39184 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done 41456 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=-1)]: Done 43792 tasks      | elapsed: 47.8min\n",
      "[Parallel(n_jobs=-1)]: Done 46192 tasks      | elapsed: 50.4min\n",
      "[Parallel(n_jobs=-1)]: Done 48656 tasks      | elapsed: 53.1min\n",
      "[Parallel(n_jobs=-1)]: Done 50400 out of 50400 | elapsed: 55.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing rf_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('rf_clf', RandomForestClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'rf_clf__bootstrap': [True, False],\n",
      "                         'rf_clf__max_depth': [16, 32, 64],\n",
      "                         'rf_clf__max_features': ['sqrt', 'log2'],\n",
      "                         'rf_clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
      "                         'rf_clf__min_samples_split': [2],\n",
      "                         'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
      "                         'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
      "                                                 <function chi2 at 0x0000018150CD8700>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.872549019607843\n",
      "\n",
      "best_params_: {'rf_clf__bootstrap': True, 'rf_clf__max_depth': 16, 'rf_clf__max_features': 'log2', 'rf_clf__min_samples_leaf': 1, 'rf_clf__min_samples_split': 2, 'rf_clf__n_estimators': 10, 'rf_clf__n_jobs': -1, 'rf_clf__random_state': 42, 'sel_per__percentile': 20, 'sel_per__score_func': <function chi2 at 0x0000018150CD8700>}\n",
      "\n",
      " 1 sel_per_empty_ab_clf \n",
      "\n",
      "Fitting 5 folds for each of 1764 candidates, totalling 8820 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 336 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 560 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 848 tasks      | elapsed:   54.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1616 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2096 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2640 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3248 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3920 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4656 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5456 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6320 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7248 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8240 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8820 out of 8820 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing ab_clf, total=   6.9s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('ab_clf', AdaBoostClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
      "                         'ab_clf__base_estimator': [DecisionTreeClassifier(random_state=42),\n",
      "                                                    RandomForestClassifier(n_jobs=-1,\n",
      "                                                                           random_state=42),\n",
      "                                                    AdaBoostClassifier(random_state=42),\n",
      "                                                    SVC(random_state=42...\n",
      "                                                    GaussianNB()],\n",
      "                         'ab_clf__n_estimators': [8, 16, 24, 32, 40, 48, 56],\n",
      "                         'ab_clf__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
      "                                                 <function chi2 at 0x0000018150CD8700>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.861437908496732\n",
      "\n",
      "best_params_: {'ab_clf__algorithm': 'SAMME.R', 'ab_clf__base_estimator': RandomForestClassifier(n_jobs=-1, random_state=42), 'ab_clf__n_estimators': 32, 'ab_clf__random_state': 42, 'sel_per__percentile': 5, 'sel_per__score_func': <function chi2 at 0x0000018150CD8700>}\n",
      "\n",
      " 2 sel_per_empty_kn_clf \n",
      "\n",
      "Fitting 5 folds for each of 7938 candidates, totalling 39690 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed:   52.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1248 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1664 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2144 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2688 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3296 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3968 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4704 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5504 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6368 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7296 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8288 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9344 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10464 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 11648 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 12896 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 14208 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 15584 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 17024 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done 18528 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done 20096 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=-1)]: Done 21728 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23424 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done 25184 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done 27008 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done 28896 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 30848 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=-1)]: Done 32864 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 34944 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=-1)]: Done 37088 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 39296 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 39690 out of 39690 | elapsed: 39.9min finished\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [187 206 207 208 209 210 225 291 298 305 317 318 319 320 321 331 332 333\n",
      " 334 339 340 346 347 350 351 352] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing kn_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('kn_clf', KNeighborsClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'kn_clf__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
      "                         'kn_clf__leaf_size': [4, 8, 12, 16, 20, 24, 30],\n",
      "                         'kn_clf__n_jobs': [-1],\n",
      "                         'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      "                         'kn_clf__weights': ['uniform', 'distance'],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
      "                                                 <function chi2 at 0x0000018150CD8700>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8725490196078433\n",
      "\n",
      "best_params_: {'kn_clf__algorithm': 'ball_tree', 'kn_clf__leaf_size': 4, 'kn_clf__n_jobs': -1, 'kn_clf__n_neighbors': 4, 'kn_clf__weights': 'distance', 'sel_per__percentile': 20, 'sel_per__score_func': <function f_classif at 0x0000018150CD83A0>}\n",
      "\n",
      " 3 sel_per_empty_gnb_clf \n",
      "\n",
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of 105 | elapsed:    5.4s remaining:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ........... (step 2 of 2) Processing gnb_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('gnb_clf', GaussianNB())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
      "                                                 <function chi2 at 0x0000018150CD8700>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.7673202614379085\n",
      "\n",
      "best_params_: {'sel_per__percentile': 2, 'sel_per__score_func': <function chi2 at 0x0000018150CD8700>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. Check the tester.py script in the final project\n",
    "### folder for details on the evaluation method, especially the test_classifier\n",
    "### function. Because of the small size of the dataset, the script uses\n",
    "### stratified shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "### Search 'em all, round 1: See first_gridsearch.ipynb in supplemental_notebooks folder.\n",
    "### Search 'em all, round 2: See second_gridsearch.ipynb in supplemental_notebooks folder.\n",
    "\n",
    "n_jobs = -1\n",
    "\n",
    "mutual_info_classif_partial = partial(mutual_info_classif, random_state=42)\n",
    "DecisionTreeClassifier_partial = partial(DecisionTreeClassifier, random_state=42)\n",
    "RandomForestClassifier_partial = partial(RandomForestClassifier, random_state=42, n_jobs=n_jobs)\n",
    "AdaBoostClassifier_partial = partial(AdaBoostClassifier, random_state=42)\n",
    "svm_SVC_partial = partial(svm.SVC, random_state=42)\n",
    "KNeighborsClassifier_partial = partial(KNeighborsClassifier, n_jobs=n_jobs)\n",
    "\n",
    "selectors = {\n",
    "    'sel_per': {\n",
    "        'sel': SelectPercentile(),\n",
    "        'params': {\n",
    "            'sel_per__score_func': [f_classif, chi2, mutual_info_classif_partial],\n",
    "            'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "decomps = {\n",
    "    'empty' : None\n",
    "#     'fica': {\n",
    "#         'dec': FastICA(),\n",
    "#         'params': {\n",
    "#             'fica__algorithm': ['parallel', 'deflation'],\n",
    "#             'fica__fun': ['logcosh', 'exp', 'cube'],\n",
    "#             'fica__random_state': [42]\n",
    "#         }\n",
    "#     }\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'rf_clf': {\n",
    "        'clf': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "            'rf_clf__max_features': ['sqrt', 'log2'],\n",
    "            'rf_clf__max_depth': [16, 32, 64],\n",
    "            'rf_clf__min_samples_split': [2],\n",
    "            'rf_clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "            'rf_clf__bootstrap': [True, False],\n",
    "            'rf_clf__random_state': [42],\n",
    "            'rf_clf__n_jobs': [n_jobs]\n",
    "        }\n",
    "    },\n",
    "    'ab_clf': {\n",
    "        'clf': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'ab_clf__base_estimator': [\n",
    "                DecisionTreeClassifier_partial(),\n",
    "                RandomForestClassifier_partial(),\n",
    "                AdaBoostClassifier_partial(),\n",
    "                svm_SVC_partial(),\n",
    "                KNeighborsClassifier_partial(),\n",
    "                GaussianNB()\n",
    "            ],\n",
    "            'ab_clf__n_estimators': [8, 16, 24, 32, 40, 48, 56],\n",
    "            'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
    "            'ab_clf__random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    'kn_clf': {\n",
    "        'clf': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'kn_clf__weights': ['uniform', 'distance'],\n",
    "            'kn_clf__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "            'kn_clf__leaf_size': [4, 8, 12, 16, 20, 24, 30],\n",
    "            'kn_clf__n_jobs': [n_jobs]\n",
    "        }\n",
    "    },\n",
    "    'gnb_clf': {\n",
    "        'clf': GaussianNB(),\n",
    "        'params': {\n",
    "            # Defaults\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "imp_gscvs_dict = {}\n",
    "imp_gscvs_dict['mixed_impute'] \\\n",
    "    = search_em_all(X_train=X_train_scaled_imp_k, y_train=y_train_1d, selectors=selectors,\n",
    "                    decomps=decomps, classifiers=classifiers, pipe_verbose=True,\n",
    "                    scoring='recall_weighted', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/imp_gscvs_dict4.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=imp_gscvs_dict, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mixed_impute': {'sel_per_empty_rf_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('rf_clf', RandomForestClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'rf_clf__bootstrap': [True, False],\n",
       "                           'rf_clf__max_depth': [16, 32, 64],\n",
       "                           'rf_clf__max_features': ['sqrt', 'log2'],\n",
       "                           'rf_clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                           'rf_clf__min_samples_split': [2],\n",
       "                           'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
       "                           'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3),\n",
       "  'sel_per_empty_ab_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('ab_clf', AdaBoostClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
       "                           'ab_clf__base_estimator': [DecisionTreeClassifier(random_state=42),\n",
       "                                                      RandomForestClassifier(n_jobs=-1,\n",
       "                                                                             random_state=42),\n",
       "                                                      AdaBoostClassifier(random_state=42),\n",
       "                                                      SVC(random_state=42...\n",
       "                                                      GaussianNB()],\n",
       "                           'ab_clf__n_estimators': [8, 16, 24, 32, 40, 48, 56],\n",
       "                           'ab_clf__random_state': [42],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3),\n",
       "  'sel_per_empty_kn_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('kn_clf', KNeighborsClassifier())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'kn_clf__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
       "                           'kn_clf__leaf_size': [4, 8, 12, 16, 20, 24, 30],\n",
       "                           'kn_clf__n_jobs': [-1],\n",
       "                           'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                           'kn_clf__weights': ['uniform', 'distance'],\n",
       "                           'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3),\n",
       "  'sel_per_empty_gnb_clf': GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
       "                                         ('gnb_clf', GaussianNB())],\n",
       "                                  verbose=True),\n",
       "               n_jobs=-1,\n",
       "               param_grid={'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
       "                           'sel_per__score_func': [<function f_classif at 0x0000018150CD83A0>,\n",
       "                                                   <function chi2 at 0x0000018150CD8700>,\n",
       "                                                   functools.partial(<function mutual_info_classif at 0x0000018150CFC280>, random_state=42)]},\n",
       "               scoring='recall_weighted', verbose=3)}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_gscvs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sel_per_empty_rf_clf \n",
      "\n",
      "Best score:\n",
      " 0.872549019607843 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per',\n",
      "                 SelectPercentile(percentile=20,\n",
      "                                  score_func=<function chi2 at 0x0000018150CD8700>)),\n",
      "                ('rf_clf',\n",
      "                 RandomForestClassifier(max_depth=16, max_features='log2',\n",
      "                                        n_estimators=10, n_jobs=-1,\n",
      "                                        random_state=42))],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing rf_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[29  2]\n",
      " [ 5  1]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.85294118, 0.33333333]), array([0.93548387, 0.16666667]), array([0.89230769, 0.22222222]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.27884615384615385 \n",
      "\n",
      "\n",
      "\n",
      "sel_per_empty_ab_clf \n",
      "\n",
      "Best score:\n",
      " 0.861437908496732 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per',\n",
      "                 SelectPercentile(percentile=5,\n",
      "                                  score_func=<function chi2 at 0x0000018150CD8700>)),\n",
      "                ('ab_clf',\n",
      "                 AdaBoostClassifier(base_estimator=RandomForestClassifier(n_jobs=-1,\n",
      "                                                                          random_state=42),\n",
      "                                    n_estimators=32, random_state=42))],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing ab_clf, total=   7.1s\n",
      "Confusion matrix:\n",
      " [[28  3]\n",
      " [ 4  2]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.875, 0.4  ]), array([0.90322581, 0.33333333]), array([0.88888889, 0.36363636]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.48275862068965514 \n",
      "\n",
      "\n",
      "\n",
      "sel_per_empty_kn_clf \n",
      "\n",
      "Best score:\n",
      " 0.8725490196078433 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per', SelectPercentile(percentile=20)),\n",
      "                ('kn_clf',\n",
      "                 KNeighborsClassifier(algorithm='ball_tree', leaf_size=4,\n",
      "                                      n_jobs=-1, n_neighbors=4,\n",
      "                                      weights='distance'))],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing kn_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[27  4]\n",
      " [ 5  1]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.84375, 0.2    ]), array([0.87096774, 0.16666667]), array([0.85714286, 0.18181818]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.2783505154639175 \n",
      "\n",
      "\n",
      "\n",
      "sel_per_empty_gnb_clf \n",
      "\n",
      "Best score:\n",
      " 0.7673202614379085 \n",
      "\n",
      "Best estimator:\n",
      " Pipeline(steps=[('sel_per',\n",
      "                 SelectPercentile(percentile=2,\n",
      "                                  score_func=<function chi2 at 0x0000018150CD8700>)),\n",
      "                ('gnb_clf', GaussianNB())],\n",
      "         verbose=True) \n",
      "\n",
      "[Pipeline] ........... (step 1 of 2) Processing sel_per, total=   0.0s\n",
      "[Pipeline] ........... (step 2 of 2) Processing gnb_clf, total=   0.0s\n",
      "Confusion matrix:\n",
      " [[22  9]\n",
      " [ 5  1]] \n",
      "\n",
      "Precision, recall, f beta score, support:\n",
      " (array([0.81481481, 0.1       ]), array([0.70967742, 0.16666667]), array([0.75862069, 0.125     ]), array([31,  6], dtype=int64)) \n",
      "\n",
      "Custom F beta using nonPOI precision and POI recall:\n",
      " 0.27672955974842767 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [187 206 207 208 209 210 225 291 298 305 317 318 319 320 321 331 332 333\n",
      " 334 339 340 346 347 350 351 352] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "get_f = lambda precision, recall: 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "for name, gscv in imp_gscvs_dict['mixed_impute'].items():\n",
    "    print(name, '\\n')\n",
    "    print('Best score:\\n', gscv.best_score_, '\\n')\n",
    "    print('Best estimator:\\n', gscv.best_estimator_, '\\n')\n",
    "    clf = gscv.best_estimator_.fit(X=X_train_scaled_imp_k, y=y_train_1d)\n",
    "    pred = clf.predict(X_test_scaled_imp_k)\n",
    "    conf = confusion_matrix(y_true=y_test_1d, y_pred=pred)\n",
    "    print('Confusion matrix:\\n', conf, '\\n')\n",
    "    prf = precision_recall_fscore_support(y_true=y_test_1d, y_pred=pred)\n",
    "    print('Precision, recall, f beta score, support:\\n', prf, '\\n')\n",
    "    print('Custom F beta using nonPOI precision and POI recall:\\n', get_f(prf[0][0], prf[1][1]), '\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation method stats:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp_mv     0.814379\n",
       "imp_med    0.791503\n",
       "imp0       0.732026\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp_mv     0.859869\n",
       "imp_med    0.859673\n",
       "imp0       0.850196\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp0       0.884314\n",
       "imp_med    0.884314\n",
       "imp_mv     0.883660\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp0       4\n",
       "imp_med    5\n",
       "imp_mv     6\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "\n",
    "selected_features_list = []\n",
    "\n",
    "#############################\n",
    "### For Udacity. Not sure I need it.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "data = featureFormat(my_dataset, selected_features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "###############################\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, selected_features_list)\n",
    "\n",
    "with open('X_train_scaled_imp0.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_train_scaled_imp0, file=file)\n",
    "with open('X_test_scaled_imp0.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_test_scaled_imp0, file=file)\n",
    "with open('data_df_scaled_imp0.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=data_df_scaled_imp0, file=file)\n",
    "    \n",
    "with open('X_train_scaled_imp_med.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_train_scaled_imp_med, file=file)\n",
    "with open('X_test_scaled_imp_med.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_test_scaled_imp_med, file=file)\n",
    "with open('data_df_scaled_imp_med.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=data_df_scaled_imp_med, file=file)\n",
    "    \n",
    "with open('X_train_scaled_imp_mv.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_train_scaled_imp_mv, file=file)\n",
    "with open('X_test_scaled_imp_mv.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=X_test_scaled_imp_mv, file=file)\n",
    "with open('data_df_scaled_imp_mv.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=data_df_scaled_imp_mv, file=file)\n",
    "\n",
    "with open('full_features_list.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=full_features_list, file=file)\n",
    "with open('selected_features_list.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=selected_features_list, file=file)\n",
    "with open('fin_features.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=fin_features, file=file)\n",
    "with open('pay_features.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=pay_features, file=file)\n",
    "with open('stock_features.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=stock_features, file=file)\n",
    "with open('email_features.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=email_features, file=file)\n",
    "with open('pay_feats_divby_lst.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=pay_feats_divby_lst, file=file)\n",
    "with open('stock_feats_divby_lst.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=stock_feats_divby_lst, file=file)\n",
    "with open('email_feats_divby_lst.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=email_feats_divby_lst, file=file)\n",
    "with open('quant_flags_lst.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=quant_flags_lst, file=file)\n",
    "with open('sign_flags_lst.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=sign_flags_lst, file=file)\n",
    "    \n",
    "with open('base_perfs_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=base_perfs_dict, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>kn_clf__n_neighbors</th>\n",
       "      <th>kn_clf__weights</th>\n",
       "      <th>kn_clf__algorithm</th>\n",
       "      <th>kn_clf__leaf_size</th>\n",
       "      <th>kn_clf__n_jobs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_method</th>\n",
       "      <th>selector</th>\n",
       "      <th>decomp</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imp0</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>kn_clf</th>\n",
       "      <td>4.0</td>\n",
       "      <td>distance</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_med</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>kn_clf</th>\n",
       "      <td>2.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_mv</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp_med</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th>ipca</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp0</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_mv</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>ipca</th>\n",
       "      <th>kn_clf</th>\n",
       "      <td>8.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imp0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ipca</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>4.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_mv</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>ipca</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_med</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>gnb_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp_mv</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fica</th>\n",
       "      <th>kn_clf</th>\n",
       "      <td>8.0</td>\n",
       "      <td>distance</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipca</th>\n",
       "      <th>ab_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       kn_clf__n_neighbors kn_clf__weights  \\\n",
       "imp_method selector decomp classifier                                        \n",
       "imp0       sel_per  fica   kn_clf                      4.0        distance   \n",
       "imp_med    sel_per  fica   kn_clf                      2.0         uniform   \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN             NaN   \n",
       "imp_med    sel_per  ipca   rf_clf                      NaN             NaN   \n",
       "                    fica   rf_clf                      NaN             NaN   \n",
       "                           ab_clf                      NaN             NaN   \n",
       "imp0       sel_per  fica   rf_clf                      NaN             NaN   \n",
       "imp_mv     sel_per  ipca   kn_clf                      8.0         uniform   \n",
       "imp0       sel_per  ipca   rf_clf                      NaN             NaN   \n",
       "                           kn_clf                      4.0         uniform   \n",
       "imp_mv     sel_per  ipca   rf_clf                      NaN             NaN   \n",
       "imp_med    sel_per  fica   gnb_clf                     NaN             NaN   \n",
       "imp_mv     sel_per  fica   kn_clf                      8.0        distance   \n",
       "                           ab_clf                      NaN             NaN   \n",
       "                    ipca   ab_clf                      NaN             NaN   \n",
       "\n",
       "                                      kn_clf__algorithm  kn_clf__leaf_size  \\\n",
       "imp_method selector decomp classifier                                        \n",
       "imp0       sel_per  fica   kn_clf             ball_tree               16.0   \n",
       "imp_med    sel_per  fica   kn_clf             ball_tree               16.0   \n",
       "imp_mv     sel_per  fica   rf_clf                   NaN                NaN   \n",
       "imp_med    sel_per  ipca   rf_clf                   NaN                NaN   \n",
       "                    fica   rf_clf                   NaN                NaN   \n",
       "                           ab_clf                   NaN                NaN   \n",
       "imp0       sel_per  fica   rf_clf                   NaN                NaN   \n",
       "imp_mv     sel_per  ipca   kn_clf             ball_tree               16.0   \n",
       "imp0       sel_per  ipca   rf_clf                   NaN                NaN   \n",
       "                           kn_clf             ball_tree               16.0   \n",
       "imp_mv     sel_per  ipca   rf_clf                   NaN                NaN   \n",
       "imp_med    sel_per  fica   gnb_clf                  NaN                NaN   \n",
       "imp_mv     sel_per  fica   kn_clf             ball_tree               32.0   \n",
       "                           ab_clf                   NaN                NaN   \n",
       "                    ipca   ab_clf                   NaN                NaN   \n",
       "\n",
       "                                       kn_clf__n_jobs  \n",
       "imp_method selector decomp classifier                  \n",
       "imp0       sel_per  fica   kn_clf                -1.0  \n",
       "imp_med    sel_per  fica   kn_clf                -1.0  \n",
       "imp_mv     sel_per  fica   rf_clf                 NaN  \n",
       "imp_med    sel_per  ipca   rf_clf                 NaN  \n",
       "                    fica   rf_clf                 NaN  \n",
       "                           ab_clf                 NaN  \n",
       "imp0       sel_per  fica   rf_clf                 NaN  \n",
       "imp_mv     sel_per  ipca   kn_clf                -1.0  \n",
       "imp0       sel_per  ipca   rf_clf                 NaN  \n",
       "                           kn_clf                -1.0  \n",
       "imp_mv     sel_per  ipca   rf_clf                 NaN  \n",
       "imp_med    sel_per  fica   gnb_clf                NaN  \n",
       "imp_mv     sel_per  fica   kn_clf                -1.0  \n",
       "                           ab_clf                 NaN  \n",
       "                    ipca   ab_clf                 NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head(15)\\\n",
    "    [classifiers['kn_clf']['params'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "imp0\n",
      "\n",
      "\n",
      " 0 sel_per_fica_rf_clf \n",
      "\n",
      "Fitting 5 folds for each of 60480 candidates, totalling 302400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 8176 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9232 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10352 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 11536 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14096 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 15472 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 16912 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18416 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done 19984 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 21616 tasks      | elapsed: 24.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23312 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25072 tasks      | elapsed: 29.0min\n",
      "[Parallel(n_jobs=-1)]: Done 26896 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28784 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 30736 tasks      | elapsed: 35.4min\n",
      "[Parallel(n_jobs=-1)]: Done 32752 tasks      | elapsed: 37.7min\n",
      "[Parallel(n_jobs=-1)]: Done 34832 tasks      | elapsed: 40.0min\n",
      "[Parallel(n_jobs=-1)]: Done 36976 tasks      | elapsed: 42.4min\n",
      "[Parallel(n_jobs=-1)]: Done 39184 tasks      | elapsed: 44.9min\n",
      "[Parallel(n_jobs=-1)]: Done 41456 tasks      | elapsed: 47.4min\n",
      "[Parallel(n_jobs=-1)]: Done 43792 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done 46192 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=-1)]: Done 48656 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=-1)]: Done 51184 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=-1)]: Done 53776 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-1)]: Done 56432 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 59152 tasks      | elapsed: 66.0min\n",
      "[Parallel(n_jobs=-1)]: Done 61936 tasks      | elapsed: 68.7min\n",
      "[Parallel(n_jobs=-1)]: Done 64784 tasks      | elapsed: 71.5min\n",
      "[Parallel(n_jobs=-1)]: Done 67696 tasks      | elapsed: 74.3min\n",
      "[Parallel(n_jobs=-1)]: Done 70672 tasks      | elapsed: 77.2min\n",
      "[Parallel(n_jobs=-1)]: Done 73712 tasks      | elapsed: 80.2min\n",
      "[Parallel(n_jobs=-1)]: Done 76816 tasks      | elapsed: 83.2min\n",
      "[Parallel(n_jobs=-1)]: Done 79984 tasks      | elapsed: 86.2min\n",
      "[Parallel(n_jobs=-1)]: Done 83216 tasks      | elapsed: 89.4min\n",
      "[Parallel(n_jobs=-1)]: Done 86512 tasks      | elapsed: 92.5min\n",
      "[Parallel(n_jobs=-1)]: Done 89872 tasks      | elapsed: 95.8min\n",
      "[Parallel(n_jobs=-1)]: Done 93296 tasks      | elapsed: 99.1min\n",
      "[Parallel(n_jobs=-1)]: Done 96784 tasks      | elapsed: 102.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100336 tasks      | elapsed: 105.8min\n",
      "[Parallel(n_jobs=-1)]: Done 103952 tasks      | elapsed: 109.1min\n",
      "[Parallel(n_jobs=-1)]: Done 107632 tasks      | elapsed: 112.3min\n",
      "[Parallel(n_jobs=-1)]: Done 111376 tasks      | elapsed: 115.6min\n",
      "[Parallel(n_jobs=-1)]: Done 115184 tasks      | elapsed: 119.0min\n",
      "[Parallel(n_jobs=-1)]: Done 119056 tasks      | elapsed: 122.4min\n",
      "[Parallel(n_jobs=-1)]: Done 122992 tasks      | elapsed: 125.9min\n",
      "[Parallel(n_jobs=-1)]: Done 126992 tasks      | elapsed: 129.5min\n",
      "[Parallel(n_jobs=-1)]: Done 131056 tasks      | elapsed: 133.0min\n",
      "[Parallel(n_jobs=-1)]: Done 135184 tasks      | elapsed: 136.6min\n",
      "[Parallel(n_jobs=-1)]: Done 139376 tasks      | elapsed: 140.3min\n",
      "[Parallel(n_jobs=-1)]: Done 143632 tasks      | elapsed: 144.0min\n",
      "[Parallel(n_jobs=-1)]: Done 147952 tasks      | elapsed: 147.8min\n",
      "[Parallel(n_jobs=-1)]: Done 152336 tasks      | elapsed: 152.8min\n",
      "[Parallel(n_jobs=-1)]: Done 156784 tasks      | elapsed: 161.2min\n",
      "[Parallel(n_jobs=-1)]: Done 161296 tasks      | elapsed: 169.7min\n",
      "[Parallel(n_jobs=-1)]: Done 165872 tasks      | elapsed: 178.4min\n",
      "[Parallel(n_jobs=-1)]: Done 170512 tasks      | elapsed: 187.2min\n",
      "[Parallel(n_jobs=-1)]: Done 175216 tasks      | elapsed: 196.1min\n",
      "[Parallel(n_jobs=-1)]: Done 179984 tasks      | elapsed: 205.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184816 tasks      | elapsed: 214.2min\n",
      "[Parallel(n_jobs=-1)]: Done 189712 tasks      | elapsed: 223.4min\n",
      "[Parallel(n_jobs=-1)]: Done 194672 tasks      | elapsed: 232.7min\n",
      "[Parallel(n_jobs=-1)]: Done 199696 tasks      | elapsed: 242.2min\n",
      "[Parallel(n_jobs=-1)]: Done 204784 tasks      | elapsed: 249.0min\n",
      "[Parallel(n_jobs=-1)]: Done 209936 tasks      | elapsed: 254.4min\n",
      "[Parallel(n_jobs=-1)]: Done 215152 tasks      | elapsed: 259.8min\n",
      "[Parallel(n_jobs=-1)]: Done 220432 tasks      | elapsed: 265.3min\n",
      "[Parallel(n_jobs=-1)]: Done 225776 tasks      | elapsed: 270.8min\n",
      "[Parallel(n_jobs=-1)]: Done 231184 tasks      | elapsed: 276.4min\n",
      "[Parallel(n_jobs=-1)]: Done 236656 tasks      | elapsed: 282.0min\n",
      "[Parallel(n_jobs=-1)]: Done 242192 tasks      | elapsed: 287.7min\n",
      "[Parallel(n_jobs=-1)]: Done 247792 tasks      | elapsed: 293.5min\n",
      "[Parallel(n_jobs=-1)]: Done 253456 tasks      | elapsed: 299.0min\n",
      "[Parallel(n_jobs=-1)]: Done 259184 tasks      | elapsed: 304.0min\n",
      "[Parallel(n_jobs=-1)]: Done 264976 tasks      | elapsed: 309.1min\n",
      "[Parallel(n_jobs=-1)]: Done 270832 tasks      | elapsed: 314.2min\n",
      "[Parallel(n_jobs=-1)]: Done 276752 tasks      | elapsed: 319.4min\n",
      "[Parallel(n_jobs=-1)]: Done 282736 tasks      | elapsed: 324.6min\n",
      "[Parallel(n_jobs=-1)]: Done 288784 tasks      | elapsed: 329.8min\n",
      "[Parallel(n_jobs=-1)]: Done 294896 tasks      | elapsed: 335.1min\n",
      "[Parallel(n_jobs=-1)]: Done 301072 tasks      | elapsed: 340.4min\n",
      "[Parallel(n_jobs=-1)]: Done 302400 out of 302400 | elapsed: 341.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing rf_clf, total=   0.0s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('rf_clf', RandomForestClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'rf_clf__bootstrap': [True, False],\n",
      "                         'rf_clf__max_depth': [16, 32, 64],\n",
      "                         'rf_clf__max_featu...\n",
      "                         'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
      "                         'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8843137254901962\n",
      "\n",
      "best_params_: {'fica__algorithm': 'parallel', 'fica__fun': 'exp', 'fica__random_state': 42, 'rf_clf__bootstrap': True, 'rf_clf__max_depth': 16, 'rf_clf__max_features': 'log2', 'rf_clf__min_samples_leaf': 3, 'rf_clf__min_samples_split': 2, 'rf_clf__n_estimators': 16, 'rf_clf__n_jobs': -1, 'rf_clf__random_state': 42, 'sel_per__percentile': 15, 'sel_per__score_func': <function chi2 at 0x0000024138DC3D30>}\n",
      "\n",
      " 1 sel_per_fica_ab_clf \n",
      "\n",
      "Fitting 5 folds for each of 756 candidates, totalling 3780 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3780 out of 3780 | elapsed:  4.2min finished\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [222 231 235 236 237 238 239 240 241 242 243 245 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 278 279 280] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 3) Processing ab_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('ab_clf', AdaBoostClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
      "                         'ab_clf__base_estimator': [GaussianNB()],\n",
      "                         'ab_clf__n_estimators': [16, 32, 48],\n",
      "                         'ab_clf__random_state': [42],\n",
      "                         'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8843137254901962\n",
      "\n",
      "best_params_: {'ab_clf__algorithm': 'SAMME.R', 'ab_clf__base_estimator': GaussianNB(), 'ab_clf__n_estimators': 16, 'ab_clf__random_state': 42, 'fica__algorithm': 'parallel', 'fica__fun': 'cube', 'fica__random_state': 42, 'sel_per__percentile': 2, 'sel_per__score_func': <function f_classif at 0x0000024138DC39D0>}\n",
      "\n",
      " 2 sel_per_fica_kn_clf \n",
      "\n",
      "Fitting 5 folds for each of 6804 candidates, totalling 34020 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 584 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=-1)]: Done 872 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1640 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2120 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2664 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3272 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3944 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4680 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5480 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6344 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7272 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8264 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9320 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10440 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11624 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 12872 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14184 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 15560 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 17000 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18504 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20072 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done 21704 tasks      | elapsed: 24.5min\n",
      "[Parallel(n_jobs=-1)]: Done 23400 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done 25160 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26984 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 28872 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 30824 tasks      | elapsed: 33.9min\n",
      "[Parallel(n_jobs=-1)]: Done 32840 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=-1)]: Done 34020 out of 34020 | elapsed: 36.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing kn_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('kn_clf', KNeighborsClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'kn_clf__algorithm': ['ball_tree'],\n",
      "                         'kn_clf__leaf_size': [8, 16, 24],\n",
      "                         'kn_clf__n_jobs': [-1],\n",
      "                         'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      "                         'kn_clf__weights': ['uniform', 'distance'],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8843137254901962\n",
      "\n",
      "best_params_: {'fica__algorithm': 'parallel', 'fica__fun': 'exp', 'fica__random_state': 42, 'kn_clf__algorithm': 'ball_tree', 'kn_clf__leaf_size': 8, 'kn_clf__n_jobs': -1, 'kn_clf__n_neighbors': 3, 'kn_clf__weights': 'uniform', 'sel_per__percentile': 10, 'sel_per__score_func': <function chi2 at 0x0000024138DC3D30>}\n",
      "\n",
      "imp_med\n",
      "\n",
      "\n",
      " 0 sel_per_fica_rf_clf \n",
      "\n",
      "Fitting 5 folds for each of 60480 candidates, totalling 302400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3896 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5432 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6296 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7224 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 8216 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9272 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10392 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11576 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12824 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 14136 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15512 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 18456 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 20024 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 21656 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=-1)]: Done 23352 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 25112 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 26936 tasks      | elapsed: 30.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28824 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 30776 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=-1)]: Done 32792 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 34872 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=-1)]: Done 37016 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=-1)]: Done 39224 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=-1)]: Done 41496 tasks      | elapsed: 47.2min\n",
      "[Parallel(n_jobs=-1)]: Done 43832 tasks      | elapsed: 49.8min\n",
      "[Parallel(n_jobs=-1)]: Done 46232 tasks      | elapsed: 52.6min\n",
      "[Parallel(n_jobs=-1)]: Done 48696 tasks      | elapsed: 55.4min\n",
      "[Parallel(n_jobs=-1)]: Done 51224 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=-1)]: Done 53816 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 56472 tasks      | elapsed: 63.2min\n",
      "[Parallel(n_jobs=-1)]: Done 59192 tasks      | elapsed: 65.8min\n",
      "[Parallel(n_jobs=-1)]: Done 61976 tasks      | elapsed: 68.6min\n",
      "[Parallel(n_jobs=-1)]: Done 64824 tasks      | elapsed: 71.3min\n",
      "[Parallel(n_jobs=-1)]: Done 67736 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=-1)]: Done 70712 tasks      | elapsed: 77.1min\n",
      "[Parallel(n_jobs=-1)]: Done 73752 tasks      | elapsed: 80.0min\n",
      "[Parallel(n_jobs=-1)]: Done 76856 tasks      | elapsed: 83.1min\n",
      "[Parallel(n_jobs=-1)]: Done 80024 tasks      | elapsed: 86.1min\n",
      "[Parallel(n_jobs=-1)]: Done 83256 tasks      | elapsed: 89.2min\n",
      "[Parallel(n_jobs=-1)]: Done 86552 tasks      | elapsed: 92.4min\n",
      "[Parallel(n_jobs=-1)]: Done 89912 tasks      | elapsed: 95.6min\n",
      "[Parallel(n_jobs=-1)]: Done 93336 tasks      | elapsed: 98.9min\n",
      "[Parallel(n_jobs=-1)]: Done 96824 tasks      | elapsed: 102.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100376 tasks      | elapsed: 105.7min\n",
      "[Parallel(n_jobs=-1)]: Done 103992 tasks      | elapsed: 109.0min\n",
      "[Parallel(n_jobs=-1)]: Done 107672 tasks      | elapsed: 112.3min\n",
      "[Parallel(n_jobs=-1)]: Done 111416 tasks      | elapsed: 115.6min\n",
      "[Parallel(n_jobs=-1)]: Done 115224 tasks      | elapsed: 119.0min\n",
      "[Parallel(n_jobs=-1)]: Done 119096 tasks      | elapsed: 122.5min\n",
      "[Parallel(n_jobs=-1)]: Done 123032 tasks      | elapsed: 126.0min\n",
      "[Parallel(n_jobs=-1)]: Done 127032 tasks      | elapsed: 129.5min\n",
      "[Parallel(n_jobs=-1)]: Done 131096 tasks      | elapsed: 133.1min\n",
      "[Parallel(n_jobs=-1)]: Done 135224 tasks      | elapsed: 136.8min\n",
      "[Parallel(n_jobs=-1)]: Done 139416 tasks      | elapsed: 140.4min\n",
      "[Parallel(n_jobs=-1)]: Done 143672 tasks      | elapsed: 144.2min\n",
      "[Parallel(n_jobs=-1)]: Done 147992 tasks      | elapsed: 148.0min\n",
      "[Parallel(n_jobs=-1)]: Done 152376 tasks      | elapsed: 153.3min\n",
      "[Parallel(n_jobs=-1)]: Done 156824 tasks      | elapsed: 162.5min\n",
      "[Parallel(n_jobs=-1)]: Done 161336 tasks      | elapsed: 171.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165912 tasks      | elapsed: 181.2min\n",
      "[Parallel(n_jobs=-1)]: Done 170552 tasks      | elapsed: 190.8min\n",
      "[Parallel(n_jobs=-1)]: Done 175256 tasks      | elapsed: 200.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180024 tasks      | elapsed: 210.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184856 tasks      | elapsed: 220.3min\n",
      "[Parallel(n_jobs=-1)]: Done 189752 tasks      | elapsed: 230.4min\n",
      "[Parallel(n_jobs=-1)]: Done 194712 tasks      | elapsed: 240.6min\n",
      "[Parallel(n_jobs=-1)]: Done 199736 tasks      | elapsed: 250.9min\n",
      "[Parallel(n_jobs=-1)]: Done 204824 tasks      | elapsed: 258.3min\n",
      "[Parallel(n_jobs=-1)]: Done 209976 tasks      | elapsed: 264.1min\n",
      "[Parallel(n_jobs=-1)]: Done 215192 tasks      | elapsed: 269.9min\n",
      "[Parallel(n_jobs=-1)]: Done 220472 tasks      | elapsed: 275.7min\n",
      "[Parallel(n_jobs=-1)]: Done 225816 tasks      | elapsed: 281.7min\n",
      "[Parallel(n_jobs=-1)]: Done 231224 tasks      | elapsed: 287.6min\n",
      "[Parallel(n_jobs=-1)]: Done 236696 tasks      | elapsed: 293.7min\n",
      "[Parallel(n_jobs=-1)]: Done 242232 tasks      | elapsed: 299.8min\n",
      "[Parallel(n_jobs=-1)]: Done 247832 tasks      | elapsed: 306.0min\n",
      "[Parallel(n_jobs=-1)]: Done 253496 tasks      | elapsed: 311.9min\n",
      "[Parallel(n_jobs=-1)]: Done 259224 tasks      | elapsed: 316.9min\n",
      "[Parallel(n_jobs=-1)]: Done 265016 tasks      | elapsed: 322.1min\n",
      "[Parallel(n_jobs=-1)]: Done 270872 tasks      | elapsed: 327.4min\n",
      "[Parallel(n_jobs=-1)]: Done 276792 tasks      | elapsed: 332.6min\n",
      "[Parallel(n_jobs=-1)]: Done 282776 tasks      | elapsed: 338.4min\n",
      "[Parallel(n_jobs=-1)]: Done 288824 tasks      | elapsed: 344.2min\n",
      "[Parallel(n_jobs=-1)]: Done 294936 tasks      | elapsed: 349.7min\n",
      "[Parallel(n_jobs=-1)]: Done 301112 tasks      | elapsed: 355.3min\n",
      "[Parallel(n_jobs=-1)]: Done 302400 out of 302400 | elapsed: 356.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing rf_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('rf_clf', RandomForestClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'rf_clf__bootstrap': [True, False],\n",
      "                         'rf_clf__max_depth': [16, 32, 64],\n",
      "                         'rf_clf__max_featu...\n",
      "                         'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
      "                         'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8954248366013072\n",
      "\n",
      "best_params_: {'fica__algorithm': 'deflation', 'fica__fun': 'exp', 'fica__random_state': 42, 'rf_clf__bootstrap': True, 'rf_clf__max_depth': 16, 'rf_clf__max_features': 'sqrt', 'rf_clf__min_samples_leaf': 3, 'rf_clf__min_samples_split': 2, 'rf_clf__n_estimators': 4, 'rf_clf__n_jobs': -1, 'rf_clf__random_state': 42, 'sel_per__percentile': 5, 'sel_per__score_func': <function chi2 at 0x0000024138DC3D30>}\n",
      "\n",
      " 1 sel_per_fica_ab_clf \n",
      "\n",
      "Fitting 5 folds for each of 756 candidates, totalling 3780 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3780 out of 3780 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.6s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing ab_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('ab_clf', AdaBoostClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
      "                         'ab_clf__base_estimator': [GaussianNB()],\n",
      "                         'ab_clf__n_estimators': [16, 32, 48],\n",
      "                         'ab_clf__random_state': [42],\n",
      "                         'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8725490196078433\n",
      "\n",
      "best_params_: {'ab_clf__algorithm': 'SAMME.R', 'ab_clf__base_estimator': GaussianNB(), 'ab_clf__n_estimators': 32, 'ab_clf__random_state': 42, 'fica__algorithm': 'parallel', 'fica__fun': 'exp', 'fica__random_state': 42, 'sel_per__percentile': 20, 'sel_per__score_func': functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)}\n",
      "\n",
      " 2 sel_per_fica_kn_clf \n",
      "\n",
      "Fitting 5 folds for each of 6804 candidates, totalling 34020 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3896 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5432 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6296 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7224 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 8216 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 9272 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10392 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 11576 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 12824 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 14136 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15512 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18456 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 20024 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 21656 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 23352 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 25112 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26936 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28824 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 30776 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=-1)]: Done 32792 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=-1)]: Done 34020 out of 34020 | elapsed: 39.6min finished\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [222 231 235 236 237 238 239 240 241 242 243 245 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 278 279 280] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing kn_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('kn_clf', KNeighborsClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'kn_clf__algorithm': ['ball_tree'],\n",
      "                         'kn_clf__leaf_size': [8, 16, 24],\n",
      "                         'kn_clf__n_jobs': [-1],\n",
      "                         'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      "                         'kn_clf__weights': ['uniform', 'distance'],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8843137254901962\n",
      "\n",
      "best_params_: {'fica__algorithm': 'parallel', 'fica__fun': 'exp', 'fica__random_state': 42, 'kn_clf__algorithm': 'ball_tree', 'kn_clf__leaf_size': 16, 'kn_clf__n_jobs': -1, 'kn_clf__n_neighbors': 3, 'kn_clf__weights': 'uniform', 'sel_per__percentile': 20, 'sel_per__score_func': <function f_classif at 0x0000024138DC39D0>}\n",
      "\n",
      "imp_mv\n",
      "\n",
      "\n",
      " 0 sel_per_fica_rf_clf \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60480 candidates, totalling 302400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3896 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5432 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6296 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7224 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8216 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9272 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 10392 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11576 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12824 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14136 tasks      | elapsed: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done 15512 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18456 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 20024 tasks      | elapsed: 20.9min\n",
      "[Parallel(n_jobs=-1)]: Done 21656 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23352 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done 25112 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 26936 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28824 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 30776 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done 32792 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done 34872 tasks      | elapsed: 36.1min\n",
      "[Parallel(n_jobs=-1)]: Done 37016 tasks      | elapsed: 38.3min\n",
      "[Parallel(n_jobs=-1)]: Done 39224 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 41496 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done 43832 tasks      | elapsed: 45.3min\n",
      "[Parallel(n_jobs=-1)]: Done 46232 tasks      | elapsed: 47.8min\n",
      "[Parallel(n_jobs=-1)]: Done 48696 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=-1)]: Done 51224 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=-1)]: Done 53816 tasks      | elapsed: 55.2min\n",
      "[Parallel(n_jobs=-1)]: Done 56472 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 59192 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=-1)]: Done 61976 tasks      | elapsed: 62.6min\n",
      "[Parallel(n_jobs=-1)]: Done 64824 tasks      | elapsed: 65.1min\n",
      "[Parallel(n_jobs=-1)]: Done 67736 tasks      | elapsed: 67.8min\n",
      "[Parallel(n_jobs=-1)]: Done 70712 tasks      | elapsed: 70.7min\n",
      "[Parallel(n_jobs=-1)]: Done 73752 tasks      | elapsed: 73.5min\n",
      "[Parallel(n_jobs=-1)]: Done 76856 tasks      | elapsed: 76.3min\n",
      "[Parallel(n_jobs=-1)]: Done 80024 tasks      | elapsed: 79.2min\n",
      "[Parallel(n_jobs=-1)]: Done 83256 tasks      | elapsed: 82.1min\n",
      "[Parallel(n_jobs=-1)]: Done 86552 tasks      | elapsed: 85.1min\n",
      "[Parallel(n_jobs=-1)]: Done 89912 tasks      | elapsed: 88.2min\n",
      "[Parallel(n_jobs=-1)]: Done 93336 tasks      | elapsed: 91.2min\n",
      "[Parallel(n_jobs=-1)]: Done 96824 tasks      | elapsed: 94.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100376 tasks      | elapsed: 97.7min\n",
      "[Parallel(n_jobs=-1)]: Done 103992 tasks      | elapsed: 100.8min\n",
      "[Parallel(n_jobs=-1)]: Done 107672 tasks      | elapsed: 103.9min\n",
      "[Parallel(n_jobs=-1)]: Done 111416 tasks      | elapsed: 107.1min\n",
      "[Parallel(n_jobs=-1)]: Done 115224 tasks      | elapsed: 110.3min\n",
      "[Parallel(n_jobs=-1)]: Done 119096 tasks      | elapsed: 113.5min\n",
      "[Parallel(n_jobs=-1)]: Done 123032 tasks      | elapsed: 116.8min\n",
      "[Parallel(n_jobs=-1)]: Done 127032 tasks      | elapsed: 120.2min\n",
      "[Parallel(n_jobs=-1)]: Done 131096 tasks      | elapsed: 123.6min\n",
      "[Parallel(n_jobs=-1)]: Done 135224 tasks      | elapsed: 127.1min\n",
      "[Parallel(n_jobs=-1)]: Done 139416 tasks      | elapsed: 130.6min\n",
      "[Parallel(n_jobs=-1)]: Done 143672 tasks      | elapsed: 134.2min\n",
      "[Parallel(n_jobs=-1)]: Done 147992 tasks      | elapsed: 137.8min\n",
      "[Parallel(n_jobs=-1)]: Done 152376 tasks      | elapsed: 142.6min\n",
      "[Parallel(n_jobs=-1)]: Done 156824 tasks      | elapsed: 150.7min\n",
      "[Parallel(n_jobs=-1)]: Done 161336 tasks      | elapsed: 158.9min\n",
      "[Parallel(n_jobs=-1)]: Done 165912 tasks      | elapsed: 167.2min\n",
      "[Parallel(n_jobs=-1)]: Done 170552 tasks      | elapsed: 175.7min\n",
      "[Parallel(n_jobs=-1)]: Done 175256 tasks      | elapsed: 184.2min\n",
      "[Parallel(n_jobs=-1)]: Done 180024 tasks      | elapsed: 192.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184856 tasks      | elapsed: 201.7min\n",
      "[Parallel(n_jobs=-1)]: Done 189752 tasks      | elapsed: 210.4min\n",
      "[Parallel(n_jobs=-1)]: Done 194712 tasks      | elapsed: 219.3min\n",
      "[Parallel(n_jobs=-1)]: Done 199736 tasks      | elapsed: 228.1min\n",
      "[Parallel(n_jobs=-1)]: Done 204824 tasks      | elapsed: 234.5min\n",
      "[Parallel(n_jobs=-1)]: Done 209976 tasks      | elapsed: 239.4min\n",
      "[Parallel(n_jobs=-1)]: Done 215192 tasks      | elapsed: 244.3min\n",
      "[Parallel(n_jobs=-1)]: Done 220472 tasks      | elapsed: 249.4min\n",
      "[Parallel(n_jobs=-1)]: Done 225816 tasks      | elapsed: 254.4min\n",
      "[Parallel(n_jobs=-1)]: Done 231224 tasks      | elapsed: 259.5min\n",
      "[Parallel(n_jobs=-1)]: Done 236696 tasks      | elapsed: 264.6min\n",
      "[Parallel(n_jobs=-1)]: Done 242232 tasks      | elapsed: 269.8min\n",
      "[Parallel(n_jobs=-1)]: Done 247832 tasks      | elapsed: 275.1min\n",
      "[Parallel(n_jobs=-1)]: Done 253496 tasks      | elapsed: 280.3min\n",
      "[Parallel(n_jobs=-1)]: Done 259224 tasks      | elapsed: 285.0min\n",
      "[Parallel(n_jobs=-1)]: Done 265016 tasks      | elapsed: 289.8min\n",
      "[Parallel(n_jobs=-1)]: Done 270872 tasks      | elapsed: 294.6min\n",
      "[Parallel(n_jobs=-1)]: Done 276792 tasks      | elapsed: 299.5min\n",
      "[Parallel(n_jobs=-1)]: Done 282776 tasks      | elapsed: 304.3min\n",
      "[Parallel(n_jobs=-1)]: Done 288824 tasks      | elapsed: 309.3min\n",
      "[Parallel(n_jobs=-1)]: Done 294936 tasks      | elapsed: 314.2min\n",
      "[Parallel(n_jobs=-1)]: Done 301112 tasks      | elapsed: 319.3min\n",
      "[Parallel(n_jobs=-1)]: Done 302400 out of 302400 | elapsed: 320.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.3s\n",
      "[Pipeline] ............ (step 3 of 3) Processing rf_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('rf_clf', RandomForestClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'rf_clf__bootstrap': [True, False],\n",
      "                         'rf_clf__max_depth': [16, 32, 64],\n",
      "                         'rf_clf__max_featu...\n",
      "                         'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
      "                         'rf_clf__n_jobs': [-1], 'rf_clf__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.8960784313725491\n",
      "\n",
      "best_params_: {'fica__algorithm': 'parallel', 'fica__fun': 'logcosh', 'fica__random_state': 42, 'rf_clf__bootstrap': True, 'rf_clf__max_depth': 16, 'rf_clf__max_features': 'sqrt', 'rf_clf__min_samples_leaf': 2, 'rf_clf__min_samples_split': 2, 'rf_clf__n_estimators': 2, 'rf_clf__n_jobs': -1, 'rf_clf__random_state': 42, 'sel_per__percentile': 25, 'sel_per__score_func': functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)}\n",
      "\n",
      " 1 sel_per_fica_ab_clf \n",
      "\n",
      "Fitting 5 folds for each of 756 candidates, totalling 3780 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3780 out of 3780 | elapsed:  3.9min finished\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [222 231 235 236 237 238 239 240 241 242 243 245 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 278 279 280] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing ab_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('ab_clf', AdaBoostClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
      "                         'ab_clf__base_estimator': [GaussianNB()],\n",
      "                         'ab_clf__n_estimators': [16, 32, 48],\n",
      "                         'ab_clf__random_state': [42],\n",
      "                         'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.872549019607843\n",
      "\n",
      "best_params_: {'ab_clf__algorithm': 'SAMME.R', 'ab_clf__base_estimator': GaussianNB(), 'ab_clf__n_estimators': 48, 'ab_clf__random_state': 42, 'fica__algorithm': 'deflation', 'fica__fun': 'exp', 'fica__random_state': 42, 'sel_per__percentile': 10, 'sel_per__score_func': <function f_classif at 0x0000024138DC39D0>}\n",
      "\n",
      " 2 sel_per_fica_kn_clf \n",
      "\n",
      "Fitting 5 folds for each of 6804 candidates, totalling 34020 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 536 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1176 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1592 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2072 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2616 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3224 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3896 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4632 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5432 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6296 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7224 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8216 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 9272 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10392 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11576 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12824 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14136 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15512 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16952 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 18456 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=-1)]: Done 20024 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 21656 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 23352 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 25112 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26936 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28824 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 30776 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=-1)]: Done 32792 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done 34020 out of 34020 | elapsed: 34.0min finished\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:114: UserWarning: Features [222 231 235 236 237 238 239 240 241 242 243 245 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 278 279 280] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 3) Processing sel_per, total=   0.0s\n",
      "[Pipeline] .............. (step 2 of 3) Processing fica, total=   0.1s\n",
      "[Pipeline] ............ (step 3 of 3) Processing kn_clf, total=   0.0s\n",
      "\n",
      " GridSearchCV(estimator=Pipeline(steps=[('sel_per', SelectPercentile()),\n",
      "                                       ('fica', FastICA()),\n",
      "                                       ('kn_clf', KNeighborsClassifier())],\n",
      "                                verbose=True),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'fica__algorithm': ['parallel', 'deflation'],\n",
      "                         'fica__fun': ['logcosh', 'exp', 'cube'],\n",
      "                         'fica__random_state': [42],\n",
      "                         'kn_clf__algorithm': ['ball_tree'],\n",
      "                         'kn_clf__leaf_size': [8, 16, 24],\n",
      "                         'kn_clf__n_jobs': [-1],\n",
      "                         'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
      "                         'kn_clf__weights': ['uniform', 'distance'],\n",
      "                         'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30],\n",
      "                         'sel_per__score_func': [<function f_classif at 0x0000024138DC39D0>,\n",
      "                                                 <function chi2 at 0x0000024138DC3D30>,\n",
      "                                                 functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]},\n",
      "             scoring='recall_weighted', verbose=3)\n",
      "\n",
      "best_score_: 0.872549019607843\n",
      "\n",
      "best_params_: {'fica__algorithm': 'parallel', 'fica__fun': 'logcosh', 'fica__random_state': 42, 'kn_clf__algorithm': 'ball_tree', 'kn_clf__leaf_size': 24, 'kn_clf__n_jobs': -1, 'kn_clf__n_neighbors': 9, 'kn_clf__weights': 'uniform', 'sel_per__percentile': 10, 'sel_per__score_func': <function f_classif at 0x0000024138DC39D0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaleb\\anaconda3\\envs\\py3\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:118: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    }
   ],
   "source": [
    "### Final search.\n",
    "\n",
    "n_jobs = -1\n",
    "\n",
    "mutual_info_classif_partial = partial(mutual_info_classif, random_state=42)\n",
    "DecisionTreeClassifier_partial = partial(DecisionTreeClassifier, random_state=42)\n",
    "RandomForestClassifier_partial = partial(RandomForestClassifier, random_state=42, n_jobs=n_jobs)\n",
    "AdaBoostClassifier_partial = partial(AdaBoostClassifier, random_state=42)\n",
    "svm_SVC_partial = partial(svm.SVC, random_state=42)\n",
    "KNeighborsClassifier_partial = partial(KNeighborsClassifier, n_jobs=n_jobs)\n",
    "\n",
    "selectors = {\n",
    "    'sel_per': {\n",
    "        'sel': SelectPercentile(),\n",
    "        'params': {\n",
    "            'sel_per__score_func': [f_classif, chi2, mutual_info_classif_partial],\n",
    "            'sel_per__percentile': [2, 5, 10, 15, 20, 25, 30]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "decomps = {\n",
    "    'fica': {\n",
    "        'dec': FastICA(),\n",
    "        'params': {\n",
    "            'fica__algorithm': ['parallel', 'deflation'],\n",
    "            'fica__fun': ['logcosh', 'exp', 'cube'],\n",
    "            'fica__random_state': [42]\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "classifiers = {\n",
    "    'rf_clf': {\n",
    "        'clf': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'rf_clf__n_estimators': [2, 4, 6, 8, 10, 12, 14, 16],\n",
    "            'rf_clf__max_features': ['sqrt', 'log2'],\n",
    "            'rf_clf__max_depth': [16, 32, 64],\n",
    "            'rf_clf__min_samples_split': [2],\n",
    "            'rf_clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "            'rf_clf__bootstrap': [True, False],\n",
    "            'rf_clf__random_state': [42],\n",
    "            'rf_clf__n_jobs': [n_jobs]\n",
    "        }\n",
    "    },\n",
    "    'ab_clf': {\n",
    "        'clf': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'ab_clf__base_estimator': [GaussianNB()],\n",
    "            'ab_clf__n_estimators': [16, 32, 48],\n",
    "            'ab_clf__algorithm': ['SAMME', 'SAMME.R'],\n",
    "            'ab_clf__random_state': [42]\n",
    "        }\n",
    "    },\n",
    "    'kn_clf': {\n",
    "        'clf': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'kn_clf__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'kn_clf__weights': ['uniform', 'distance'],\n",
    "            'kn_clf__algorithm': ['ball_tree'],\n",
    "            'kn_clf__leaf_size': [8, 16, 24],\n",
    "            'kn_clf__n_jobs': [n_jobs]\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "imp_gscvs_dict = {}\n",
    "print('\\nimp0\\n')\n",
    "imp_gscvs_dict['imp0'] = search_em_all(X_train=X_train_scaled_imp0)\n",
    "print('\\nimp_med\\n')\n",
    "imp_gscvs_dict['imp_med'] = search_em_all(X_train=X_train_scaled_imp_med)\n",
    "print('\\nimp_mv\\n')\n",
    "imp_gscvs_dict['imp_mv'] = search_em_all(X_train=X_train_scaled_imp_mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imp_gscvs_dict_2.pkl', 'wb') as file:\n",
    "    pickle.dump(obj=imp_gscvs_dict, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9 entries, ('imp0', 'sel_per', 'fica', 'rf_clf') to ('imp_mv', 'sel_per', 'fica', 'kn_clf')\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   best_score_                9 non-null      float64\n",
      " 1   gscv                       9 non-null      object \n",
      " 2   fica__algorithm            9 non-null      object \n",
      " 3   fica__fun                  9 non-null      object \n",
      " 4   fica__random_state         9 non-null      float64\n",
      " 5   rf_clf__bootstrap          3 non-null      float64\n",
      " 6   rf_clf__max_depth          3 non-null      float64\n",
      " 7   rf_clf__max_features       3 non-null      object \n",
      " 8   rf_clf__min_samples_leaf   3 non-null      float64\n",
      " 9   rf_clf__min_samples_split  3 non-null      float64\n",
      " 10  rf_clf__n_estimators       3 non-null      float64\n",
      " 11  rf_clf__n_jobs             3 non-null      float64\n",
      " 12  rf_clf__random_state       3 non-null      float64\n",
      " 13  sel_per__percentile        9 non-null      float64\n",
      " 14  sel_per__score_func        9 non-null      object \n",
      " 15  ab_clf__algorithm          3 non-null      object \n",
      " 16  ab_clf__base_estimator     3 non-null      object \n",
      " 17  ab_clf__n_estimators       3 non-null      float64\n",
      " 18  ab_clf__random_state       3 non-null      float64\n",
      " 19  kn_clf__algorithm          3 non-null      object \n",
      " 20  kn_clf__leaf_size          3 non-null      float64\n",
      " 21  kn_clf__n_jobs             3 non-null      float64\n",
      " 22  kn_clf__n_neighbors        3 non-null      float64\n",
      " 23  kn_clf__weights            3 non-null      object \n",
      "dtypes: float64(15), object(9)\n",
      "memory usage: 2.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>best_score_</th>\n",
       "      <th>gscv</th>\n",
       "      <th>fica__algorithm</th>\n",
       "      <th>fica__fun</th>\n",
       "      <th>fica__random_state</th>\n",
       "      <th>rf_clf__bootstrap</th>\n",
       "      <th>rf_clf__max_depth</th>\n",
       "      <th>rf_clf__max_features</th>\n",
       "      <th>rf_clf__min_samples_leaf</th>\n",
       "      <th>rf_clf__min_samples_split</th>\n",
       "      <th>...</th>\n",
       "      <th>sel_per__score_func</th>\n",
       "      <th>ab_clf__algorithm</th>\n",
       "      <th>ab_clf__base_estimator</th>\n",
       "      <th>ab_clf__n_estimators</th>\n",
       "      <th>ab_clf__random_state</th>\n",
       "      <th>kn_clf__algorithm</th>\n",
       "      <th>kn_clf__leaf_size</th>\n",
       "      <th>kn_clf__n_jobs</th>\n",
       "      <th>kn_clf__n_neighbors</th>\n",
       "      <th>kn_clf__weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_method</th>\n",
       "      <th>selector</th>\n",
       "      <th>decomp</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>cube</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp_med</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.895425</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>deflation</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>functools.partial(&lt;function mutual_info_classi...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp_mv</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.896078</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>functools.partial(&lt;function mutual_info_classi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>deflation</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       best_score_  \\\n",
       "imp_method selector decomp classifier                \n",
       "imp0       sel_per  fica   rf_clf         0.884314   \n",
       "                           ab_clf         0.884314   \n",
       "                           kn_clf         0.884314   \n",
       "imp_med    sel_per  fica   rf_clf         0.895425   \n",
       "                           ab_clf         0.872549   \n",
       "                           kn_clf         0.884314   \n",
       "imp_mv     sel_per  fica   rf_clf         0.896078   \n",
       "                           ab_clf         0.872549   \n",
       "                           kn_clf         0.872549   \n",
       "\n",
       "                                                                                    gscv  \\\n",
       "imp_method selector decomp classifier                                                      \n",
       "imp0       sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp_med    sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp_mv     sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "\n",
       "                                      fica__algorithm fica__fun  \\\n",
       "imp_method selector decomp classifier                             \n",
       "imp0       sel_per  fica   rf_clf            parallel       exp   \n",
       "                           ab_clf            parallel      cube   \n",
       "                           kn_clf            parallel       exp   \n",
       "imp_med    sel_per  fica   rf_clf           deflation       exp   \n",
       "                           ab_clf            parallel       exp   \n",
       "                           kn_clf            parallel       exp   \n",
       "imp_mv     sel_per  fica   rf_clf            parallel   logcosh   \n",
       "                           ab_clf           deflation       exp   \n",
       "                           kn_clf            parallel   logcosh   \n",
       "\n",
       "                                       fica__random_state  rf_clf__bootstrap  \\\n",
       "imp_method selector decomp classifier                                          \n",
       "imp0       sel_per  fica   rf_clf                    42.0                1.0   \n",
       "                           ab_clf                    42.0                NaN   \n",
       "                           kn_clf                    42.0                NaN   \n",
       "imp_med    sel_per  fica   rf_clf                    42.0                1.0   \n",
       "                           ab_clf                    42.0                NaN   \n",
       "                           kn_clf                    42.0                NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                    42.0                1.0   \n",
       "                           ab_clf                    42.0                NaN   \n",
       "                           kn_clf                    42.0                NaN   \n",
       "\n",
       "                                       rf_clf__max_depth rf_clf__max_features  \\\n",
       "imp_method selector decomp classifier                                           \n",
       "imp0       sel_per  fica   rf_clf                   16.0                 log2   \n",
       "                           ab_clf                    NaN                  NaN   \n",
       "                           kn_clf                    NaN                  NaN   \n",
       "imp_med    sel_per  fica   rf_clf                   16.0                 sqrt   \n",
       "                           ab_clf                    NaN                  NaN   \n",
       "                           kn_clf                    NaN                  NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                   16.0                 sqrt   \n",
       "                           ab_clf                    NaN                  NaN   \n",
       "                           kn_clf                    NaN                  NaN   \n",
       "\n",
       "                                       rf_clf__min_samples_leaf  \\\n",
       "imp_method selector decomp classifier                             \n",
       "imp0       sel_per  fica   rf_clf                           3.0   \n",
       "                           ab_clf                           NaN   \n",
       "                           kn_clf                           NaN   \n",
       "imp_med    sel_per  fica   rf_clf                           3.0   \n",
       "                           ab_clf                           NaN   \n",
       "                           kn_clf                           NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                           2.0   \n",
       "                           ab_clf                           NaN   \n",
       "                           kn_clf                           NaN   \n",
       "\n",
       "                                       rf_clf__min_samples_split  ...  \\\n",
       "imp_method selector decomp classifier                             ...   \n",
       "imp0       sel_per  fica   rf_clf                            2.0  ...   \n",
       "                           ab_clf                            NaN  ...   \n",
       "                           kn_clf                            NaN  ...   \n",
       "imp_med    sel_per  fica   rf_clf                            2.0  ...   \n",
       "                           ab_clf                            NaN  ...   \n",
       "                           kn_clf                            NaN  ...   \n",
       "imp_mv     sel_per  fica   rf_clf                            2.0  ...   \n",
       "                           ab_clf                            NaN  ...   \n",
       "                           kn_clf                            NaN  ...   \n",
       "\n",
       "                                                                     sel_per__score_func  \\\n",
       "imp_method selector decomp classifier                                                      \n",
       "imp0       sel_per  fica   rf_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "                           ab_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "                           kn_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "imp_med    sel_per  fica   rf_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "                           ab_clf      functools.partial(<function mutual_info_classi...   \n",
       "                           kn_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "imp_mv     sel_per  fica   rf_clf      functools.partial(<function mutual_info_classi...   \n",
       "                           ab_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "                           kn_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "\n",
       "                                       ab_clf__algorithm  \\\n",
       "imp_method selector decomp classifier                      \n",
       "imp0       sel_per  fica   rf_clf                    NaN   \n",
       "                           ab_clf                SAMME.R   \n",
       "                           kn_clf                    NaN   \n",
       "imp_med    sel_per  fica   rf_clf                    NaN   \n",
       "                           ab_clf                SAMME.R   \n",
       "                           kn_clf                    NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                    NaN   \n",
       "                           ab_clf                SAMME.R   \n",
       "                           kn_clf                    NaN   \n",
       "\n",
       "                                       ab_clf__base_estimator  \\\n",
       "imp_method selector decomp classifier                           \n",
       "imp0       sel_per  fica   rf_clf                         NaN   \n",
       "                           ab_clf                GaussianNB()   \n",
       "                           kn_clf                         NaN   \n",
       "imp_med    sel_per  fica   rf_clf                         NaN   \n",
       "                           ab_clf                GaussianNB()   \n",
       "                           kn_clf                         NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                         NaN   \n",
       "                           ab_clf                GaussianNB()   \n",
       "                           kn_clf                         NaN   \n",
       "\n",
       "                                       ab_clf__n_estimators  \\\n",
       "imp_method selector decomp classifier                         \n",
       "imp0       sel_per  fica   rf_clf                       NaN   \n",
       "                           ab_clf                      16.0   \n",
       "                           kn_clf                       NaN   \n",
       "imp_med    sel_per  fica   rf_clf                       NaN   \n",
       "                           ab_clf                      32.0   \n",
       "                           kn_clf                       NaN   \n",
       "imp_mv     sel_per  fica   rf_clf                       NaN   \n",
       "                           ab_clf                      48.0   \n",
       "                           kn_clf                       NaN   \n",
       "\n",
       "                                      ab_clf__random_state kn_clf__algorithm  \\\n",
       "imp_method selector decomp classifier                                          \n",
       "imp0       sel_per  fica   rf_clf                      NaN               NaN   \n",
       "                           ab_clf                     42.0               NaN   \n",
       "                           kn_clf                      NaN         ball_tree   \n",
       "imp_med    sel_per  fica   rf_clf                      NaN               NaN   \n",
       "                           ab_clf                     42.0               NaN   \n",
       "                           kn_clf                      NaN         ball_tree   \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN               NaN   \n",
       "                           ab_clf                     42.0               NaN   \n",
       "                           kn_clf                      NaN         ball_tree   \n",
       "\n",
       "                                      kn_clf__leaf_size  kn_clf__n_jobs  \\\n",
       "imp_method selector decomp classifier                                     \n",
       "imp0       sel_per  fica   rf_clf                   NaN             NaN   \n",
       "                           ab_clf                   NaN             NaN   \n",
       "                           kn_clf                   8.0            -1.0   \n",
       "imp_med    sel_per  fica   rf_clf                   NaN             NaN   \n",
       "                           ab_clf                   NaN             NaN   \n",
       "                           kn_clf                  16.0            -1.0   \n",
       "imp_mv     sel_per  fica   rf_clf                   NaN             NaN   \n",
       "                           ab_clf                   NaN             NaN   \n",
       "                           kn_clf                  24.0            -1.0   \n",
       "\n",
       "                                       kn_clf__n_neighbors kn_clf__weights  \n",
       "imp_method selector decomp classifier                                       \n",
       "imp0       sel_per  fica   rf_clf                      NaN             NaN  \n",
       "                           ab_clf                      NaN             NaN  \n",
       "                           kn_clf                      3.0         uniform  \n",
       "imp_med    sel_per  fica   rf_clf                      NaN             NaN  \n",
       "                           ab_clf                      NaN             NaN  \n",
       "                           kn_clf                      3.0         uniform  \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN             NaN  \n",
       "                           ab_clf                      NaN             NaN  \n",
       "                           kn_clf                      9.0         uniform  \n",
       "\n",
       "[9 rows x 24 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Well, that was silly of me to return my search data in this structure.\n",
    "### Reformat and expand data into a dataframe.\n",
    "imp_gscvs_df = pd.DataFrame(columns=['imp_method', 'selector', 'decomp', 'classifier', 'best_score_',\n",
    "                                     'gscv'])\n",
    "\n",
    "for imp, gscv_dict in imp_gscvs_dict.items():\n",
    "    for steps_name, gscv in gscv_dict.items():\n",
    "        row_dict = {'imp_method': imp}\n",
    "        \n",
    "        steps_lst = steps_name.split('_')\n",
    "        if len(steps_lst) == 5:\n",
    "            row_dict['selector'] = '_'.join(steps_lst[:2])\n",
    "            row_dict['decomp'] = steps_lst[2]\n",
    "            row_dict['classifier'] = '_'.join(steps_lst[3:])\n",
    "            row_dict['best_score_'] = gscv.best_score_\n",
    "            row_dict['gscv'] = gscv\n",
    "        \n",
    "        row_dict.update(gscv.best_params_)\n",
    "        imp_gscvs_df = imp_gscvs_df.append(row_dict, ignore_index=True)\n",
    "        \n",
    "imp_gscvs_df = imp_gscvs_df.set_index(keys=['imp_method', 'selector', 'decomp', 'classifier'])\n",
    "imp_gscvs_df.info()\n",
    "imp_gscvs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores sorted:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>best_score_</th>\n",
       "      <th>gscv</th>\n",
       "      <th>fica__algorithm</th>\n",
       "      <th>fica__fun</th>\n",
       "      <th>fica__random_state</th>\n",
       "      <th>rf_clf__bootstrap</th>\n",
       "      <th>rf_clf__max_depth</th>\n",
       "      <th>rf_clf__max_features</th>\n",
       "      <th>rf_clf__min_samples_leaf</th>\n",
       "      <th>rf_clf__min_samples_split</th>\n",
       "      <th>...</th>\n",
       "      <th>sel_per__score_func</th>\n",
       "      <th>ab_clf__algorithm</th>\n",
       "      <th>ab_clf__base_estimator</th>\n",
       "      <th>ab_clf__n_estimators</th>\n",
       "      <th>ab_clf__random_state</th>\n",
       "      <th>kn_clf__algorithm</th>\n",
       "      <th>kn_clf__leaf_size</th>\n",
       "      <th>kn_clf__n_jobs</th>\n",
       "      <th>kn_clf__n_neighbors</th>\n",
       "      <th>kn_clf__weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_method</th>\n",
       "      <th>selector</th>\n",
       "      <th>decomp</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imp_mv</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.896078</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>functools.partial(&lt;function mutual_info_classi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_med</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.895425</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>deflation</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>cube</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function chi2 at 0x0000024138DC3D30&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imp_med</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fica</th>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.884314</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>functools.partial(&lt;function mutual_info_classi...</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>32.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">imp_mv</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">fica</th>\n",
       "      <th>ab_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>deflation</td>\n",
       "      <td>exp</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>0.872549</td>\n",
       "      <td>GridSearchCV(estimator=Pipeline(steps=[('sel_p...</td>\n",
       "      <td>parallel</td>\n",
       "      <td>logcosh</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;function f_classif at 0x0000024138DC39D0&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       best_score_  \\\n",
       "imp_method selector decomp classifier                \n",
       "imp_mv     sel_per  fica   rf_clf         0.896078   \n",
       "imp_med    sel_per  fica   rf_clf         0.895425   \n",
       "imp0       sel_per  fica   rf_clf         0.884314   \n",
       "                           ab_clf         0.884314   \n",
       "                           kn_clf         0.884314   \n",
       "imp_med    sel_per  fica   kn_clf         0.884314   \n",
       "                           ab_clf         0.872549   \n",
       "imp_mv     sel_per  fica   ab_clf         0.872549   \n",
       "                           kn_clf         0.872549   \n",
       "\n",
       "                                                                                    gscv  \\\n",
       "imp_method selector decomp classifier                                                      \n",
       "imp_mv     sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp_med    sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp0       sel_per  fica   rf_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp_med    sel_per  fica   kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "imp_mv     sel_per  fica   ab_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "                           kn_clf      GridSearchCV(estimator=Pipeline(steps=[('sel_p...   \n",
       "\n",
       "                                      fica__algorithm fica__fun  \\\n",
       "imp_method selector decomp classifier                             \n",
       "imp_mv     sel_per  fica   rf_clf            parallel   logcosh   \n",
       "imp_med    sel_per  fica   rf_clf           deflation       exp   \n",
       "imp0       sel_per  fica   rf_clf            parallel       exp   \n",
       "                           ab_clf            parallel      cube   \n",
       "                           kn_clf            parallel       exp   \n",
       "imp_med    sel_per  fica   kn_clf            parallel       exp   \n",
       "                           ab_clf            parallel       exp   \n",
       "imp_mv     sel_per  fica   ab_clf           deflation       exp   \n",
       "                           kn_clf            parallel   logcosh   \n",
       "\n",
       "                                       fica__random_state  rf_clf__bootstrap  \\\n",
       "imp_method selector decomp classifier                                          \n",
       "imp_mv     sel_per  fica   rf_clf                    42.0                1.0   \n",
       "imp_med    sel_per  fica   rf_clf                    42.0                1.0   \n",
       "imp0       sel_per  fica   rf_clf                    42.0                1.0   \n",
       "                           ab_clf                    42.0                NaN   \n",
       "                           kn_clf                    42.0                NaN   \n",
       "imp_med    sel_per  fica   kn_clf                    42.0                NaN   \n",
       "                           ab_clf                    42.0                NaN   \n",
       "imp_mv     sel_per  fica   ab_clf                    42.0                NaN   \n",
       "                           kn_clf                    42.0                NaN   \n",
       "\n",
       "                                       rf_clf__max_depth rf_clf__max_features  \\\n",
       "imp_method selector decomp classifier                                           \n",
       "imp_mv     sel_per  fica   rf_clf                   16.0                 sqrt   \n",
       "imp_med    sel_per  fica   rf_clf                   16.0                 sqrt   \n",
       "imp0       sel_per  fica   rf_clf                   16.0                 log2   \n",
       "                           ab_clf                    NaN                  NaN   \n",
       "                           kn_clf                    NaN                  NaN   \n",
       "imp_med    sel_per  fica   kn_clf                    NaN                  NaN   \n",
       "                           ab_clf                    NaN                  NaN   \n",
       "imp_mv     sel_per  fica   ab_clf                    NaN                  NaN   \n",
       "                           kn_clf                    NaN                  NaN   \n",
       "\n",
       "                                       rf_clf__min_samples_leaf  \\\n",
       "imp_method selector decomp classifier                             \n",
       "imp_mv     sel_per  fica   rf_clf                           2.0   \n",
       "imp_med    sel_per  fica   rf_clf                           3.0   \n",
       "imp0       sel_per  fica   rf_clf                           3.0   \n",
       "                           ab_clf                           NaN   \n",
       "                           kn_clf                           NaN   \n",
       "imp_med    sel_per  fica   kn_clf                           NaN   \n",
       "                           ab_clf                           NaN   \n",
       "imp_mv     sel_per  fica   ab_clf                           NaN   \n",
       "                           kn_clf                           NaN   \n",
       "\n",
       "                                       rf_clf__min_samples_split  ...  \\\n",
       "imp_method selector decomp classifier                             ...   \n",
       "imp_mv     sel_per  fica   rf_clf                            2.0  ...   \n",
       "imp_med    sel_per  fica   rf_clf                            2.0  ...   \n",
       "imp0       sel_per  fica   rf_clf                            2.0  ...   \n",
       "                           ab_clf                            NaN  ...   \n",
       "                           kn_clf                            NaN  ...   \n",
       "imp_med    sel_per  fica   kn_clf                            NaN  ...   \n",
       "                           ab_clf                            NaN  ...   \n",
       "imp_mv     sel_per  fica   ab_clf                            NaN  ...   \n",
       "                           kn_clf                            NaN  ...   \n",
       "\n",
       "                                                                     sel_per__score_func  \\\n",
       "imp_method selector decomp classifier                                                      \n",
       "imp_mv     sel_per  fica   rf_clf      functools.partial(<function mutual_info_classi...   \n",
       "imp_med    sel_per  fica   rf_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "imp0       sel_per  fica   rf_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "                           ab_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "                           kn_clf                  <function chi2 at 0x0000024138DC3D30>   \n",
       "imp_med    sel_per  fica   kn_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "                           ab_clf      functools.partial(<function mutual_info_classi...   \n",
       "imp_mv     sel_per  fica   ab_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "                           kn_clf             <function f_classif at 0x0000024138DC39D0>   \n",
       "\n",
       "                                       ab_clf__algorithm  \\\n",
       "imp_method selector decomp classifier                      \n",
       "imp_mv     sel_per  fica   rf_clf                    NaN   \n",
       "imp_med    sel_per  fica   rf_clf                    NaN   \n",
       "imp0       sel_per  fica   rf_clf                    NaN   \n",
       "                           ab_clf                SAMME.R   \n",
       "                           kn_clf                    NaN   \n",
       "imp_med    sel_per  fica   kn_clf                    NaN   \n",
       "                           ab_clf                SAMME.R   \n",
       "imp_mv     sel_per  fica   ab_clf                SAMME.R   \n",
       "                           kn_clf                    NaN   \n",
       "\n",
       "                                       ab_clf__base_estimator  \\\n",
       "imp_method selector decomp classifier                           \n",
       "imp_mv     sel_per  fica   rf_clf                         NaN   \n",
       "imp_med    sel_per  fica   rf_clf                         NaN   \n",
       "imp0       sel_per  fica   rf_clf                         NaN   \n",
       "                           ab_clf                GaussianNB()   \n",
       "                           kn_clf                         NaN   \n",
       "imp_med    sel_per  fica   kn_clf                         NaN   \n",
       "                           ab_clf                GaussianNB()   \n",
       "imp_mv     sel_per  fica   ab_clf                GaussianNB()   \n",
       "                           kn_clf                         NaN   \n",
       "\n",
       "                                       ab_clf__n_estimators  \\\n",
       "imp_method selector decomp classifier                         \n",
       "imp_mv     sel_per  fica   rf_clf                       NaN   \n",
       "imp_med    sel_per  fica   rf_clf                       NaN   \n",
       "imp0       sel_per  fica   rf_clf                       NaN   \n",
       "                           ab_clf                      16.0   \n",
       "                           kn_clf                       NaN   \n",
       "imp_med    sel_per  fica   kn_clf                       NaN   \n",
       "                           ab_clf                      32.0   \n",
       "imp_mv     sel_per  fica   ab_clf                      48.0   \n",
       "                           kn_clf                       NaN   \n",
       "\n",
       "                                      ab_clf__random_state kn_clf__algorithm  \\\n",
       "imp_method selector decomp classifier                                          \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN               NaN   \n",
       "imp_med    sel_per  fica   rf_clf                      NaN               NaN   \n",
       "imp0       sel_per  fica   rf_clf                      NaN               NaN   \n",
       "                           ab_clf                     42.0               NaN   \n",
       "                           kn_clf                      NaN         ball_tree   \n",
       "imp_med    sel_per  fica   kn_clf                      NaN         ball_tree   \n",
       "                           ab_clf                     42.0               NaN   \n",
       "imp_mv     sel_per  fica   ab_clf                     42.0               NaN   \n",
       "                           kn_clf                      NaN         ball_tree   \n",
       "\n",
       "                                      kn_clf__leaf_size  kn_clf__n_jobs  \\\n",
       "imp_method selector decomp classifier                                     \n",
       "imp_mv     sel_per  fica   rf_clf                   NaN             NaN   \n",
       "imp_med    sel_per  fica   rf_clf                   NaN             NaN   \n",
       "imp0       sel_per  fica   rf_clf                   NaN             NaN   \n",
       "                           ab_clf                   NaN             NaN   \n",
       "                           kn_clf                   8.0            -1.0   \n",
       "imp_med    sel_per  fica   kn_clf                  16.0            -1.0   \n",
       "                           ab_clf                   NaN             NaN   \n",
       "imp_mv     sel_per  fica   ab_clf                   NaN             NaN   \n",
       "                           kn_clf                  24.0            -1.0   \n",
       "\n",
       "                                       kn_clf__n_neighbors kn_clf__weights  \n",
       "imp_method selector decomp classifier                                       \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN             NaN  \n",
       "imp_med    sel_per  fica   rf_clf                      NaN             NaN  \n",
       "imp0       sel_per  fica   rf_clf                      NaN             NaN  \n",
       "                           ab_clf                      NaN             NaN  \n",
       "                           kn_clf                      3.0         uniform  \n",
       "imp_med    sel_per  fica   kn_clf                      3.0         uniform  \n",
       "                           ab_clf                      NaN             NaN  \n",
       "imp_mv     sel_per  fica   ab_clf                      NaN             NaN  \n",
       "                           kn_clf                      9.0         uniform  \n",
       "\n",
       "[9 rows x 24 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sort by best_score_.\n",
    "print('Best scores sorted:\\n')\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier stats:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "classifier\n",
       "rf_clf    0.884314\n",
       "ab_clf    0.872549\n",
       "kn_clf    0.872549\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "classifier\n",
       "rf_clf    0.891939\n",
       "kn_clf    0.880392\n",
       "ab_clf    0.876471\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "classifier\n",
       "rf_clf    0.896078\n",
       "ab_clf    0.884314\n",
       "kn_clf    0.884314\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "classifier\n",
       "ab_clf    1\n",
       "kn_clf    1\n",
       "rf_clf    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__n_estimators :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__n_estimators\n",
       "16.0    1\n",
       "4.0     1\n",
       "2.0     1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__n_estimators\n",
       "2.0     1\n",
       "4.0     1\n",
       "16.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__max_features :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sqrt', 'log2']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__max_features\n",
       "log2    1\n",
       "sqrt    2\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__max_features\n",
       "sqrt    2\n",
       "log2    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__max_depth :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16, 32, 64]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__max_depth\n",
       "16.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__max_depth\n",
       "16.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__min_samples_split :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__min_samples_split\n",
       "2.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__min_samples_split\n",
       "2.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__min_samples_leaf :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__min_samples_leaf\n",
       "3.0    2\n",
       "2.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__min_samples_leaf\n",
       "2.0    1\n",
       "3.0    2\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__bootstrap :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__bootstrap\n",
       "1.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__bootstrap\n",
       "1.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__random_state :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__random_state\n",
       "42.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__random_state\n",
       "42.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of RandomForestClassifier() best rf_clf__n_jobs :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__n_jobs\n",
       "-1.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "rf_clf__n_jobs\n",
       "-1.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of AdaBoostClassifier() best ab_clf__base_estimator :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[GaussianNB()]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__base_estimator\n",
       "GaussianNB()    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__base_estimator\n",
       "GaussianNB()    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of AdaBoostClassifier() best ab_clf__n_estimators :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16, 32, 48]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__n_estimators\n",
       "16.0    1\n",
       "32.0    1\n",
       "48.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__n_estimators\n",
       "16.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of AdaBoostClassifier() best ab_clf__algorithm :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SAMME', 'SAMME.R']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__algorithm\n",
       "SAMME.R    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__algorithm\n",
       "SAMME.R    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of AdaBoostClassifier() best ab_clf__random_state :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__random_state\n",
       "42.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ab_clf__random_state\n",
       "42.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of KNeighborsClassifier() best kn_clf__n_neighbors :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__n_neighbors\n",
       "3.0    2\n",
       "9.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__n_neighbors\n",
       "3.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of KNeighborsClassifier() best kn_clf__weights :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['uniform', 'distance']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__weights\n",
       "uniform    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__weights\n",
       "uniform    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of KNeighborsClassifier() best kn_clf__algorithm :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ball_tree']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__algorithm\n",
       "ball_tree    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__algorithm\n",
       "ball_tree    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of KNeighborsClassifier() best kn_clf__leaf_size :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 16, 24]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__leaf_size\n",
       "8.0     1\n",
       "16.0    1\n",
       "24.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__leaf_size\n",
       "8.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of KNeighborsClassifier() best kn_clf__n_jobs :\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__n_jobs\n",
       "-1.0    3\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "kn_clf__n_jobs\n",
       "-1.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nClassifier stats:\\n')\n",
    "imp_gscvs_df.groupby(by='classifier')['best_score_'].min().sort_values(ascending=False)\n",
    "imp_gscvs_df.groupby(by='classifier')['best_score_'].mean().sort_values(ascending=False)\n",
    "imp_gscvs_df.groupby(by='classifier')['best_score_'].max().sort_values(ascending=False)\n",
    "\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head().groupby(by='classifier')\\\n",
    "    ['best_score_'].count()\n",
    "\n",
    "### Groupby classifier parameters.\n",
    "for clf, clf_dict in classifiers.items():\n",
    "    for param in clf_dict['params'].keys():\n",
    "        print('Count of', str(clf_dict['clf']), 'best', param, ':')\n",
    "        print('Possible values:')\n",
    "        clf_dict['params'][param]\n",
    "        imp_gscvs_df.groupby(by=param, sort=False)['best_score_'].count()\n",
    "        imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "            .groupby(by=param, sort=False)['best_score_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of FastICA best algorithms:\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['parallel', 'deflation']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fica__algorithm\n",
       "deflation    2\n",
       "parallel     7\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fica__algorithm\n",
       "deflation    1\n",
       "parallel     4\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of FastICA best functions:\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logcosh', 'exp', 'cube']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fica__fun\n",
       "cube       1\n",
       "exp        6\n",
       "logcosh    2\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fica__fun\n",
       "cube       1\n",
       "exp        3\n",
       "logcosh    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Groupby decomp parameters.\n",
    "print('Count of FastICA best algorithms:')\n",
    "print('Possible values:')\n",
    "decomps['fica']['params']['fica__algorithm']\n",
    "imp_gscvs_df.groupby(by='fica__algorithm')['best_score_'].count()\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "    .groupby(by='fica__algorithm')['best_score_'].count()\n",
    "\n",
    "print('Count of FastICA best functions:')\n",
    "print('Possible values:')\n",
    "decomps['fica']['params']['fica__fun']\n",
    "imp_gscvs_df.groupby(by='fica__fun')['best_score_'].count()\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "    .groupby(by='fica__fun')['best_score_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of SelectPercentile best score functions:\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<function sklearn.feature_selection._univariate_selection.f_classif(X, y)>,\n",
       " <function sklearn.feature_selection._univariate_selection.chi2(X, y)>,\n",
       " functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sel_per__score_func\n",
       "<function chi2 at 0x0000024138DC3D30>                                                       3\n",
       "<function f_classif at 0x0000024138DC39D0>                                                  4\n",
       "functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)    2\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sel_per__score_func\n",
       "functools.partial(<function mutual_info_classif at 0x00000241390F9040>, random_state=42)    1\n",
       "<function chi2 at 0x0000024138DC3D30>                                                       3\n",
       "<function f_classif at 0x0000024138DC39D0>                                                  1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of SelectPercentile best percentiles:\n",
      "Possible values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 5, 10, 15, 20, 25, 30]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sel_per__percentile\n",
       "2.0     1\n",
       "5.0     1\n",
       "10.0    3\n",
       "15.0    1\n",
       "20.0    2\n",
       "25.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "sel_per__percentile\n",
       "2.0     1\n",
       "5.0     1\n",
       "10.0    1\n",
       "15.0    1\n",
       "25.0    1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###  Groupby selector parameters.\n",
    "print('Count of SelectPercentile best score functions:')\n",
    "print('Possible values:')\n",
    "selectors['sel_per']['params']['sel_per__score_func']\n",
    "imp_gscvs_df.groupby(by='sel_per__score_func', sort=False)['best_score_'].count()\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "    .groupby(by='sel_per__score_func', sort=False)['best_score_'].count()\n",
    "\n",
    "print('Count of SelectPercentile best percentiles:')\n",
    "print('Possible values:')\n",
    "selectors['sel_per']['params']['sel_per__percentile']\n",
    "imp_gscvs_df.groupby(by='sel_per__percentile')['best_score_'].count()\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "    .groupby(by='sel_per__percentile')['best_score_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputation method stats:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp0       0.884314\n",
       "imp_med    0.872549\n",
       "imp_mv     0.872549\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp0       0.884314\n",
       "imp_med    0.884096\n",
       "imp_mv     0.880392\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp_mv     0.896078\n",
       "imp_med    0.895425\n",
       "imp0       0.884314\n",
       "Name: best_score_, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "imp_method\n",
       "imp0       3\n",
       "imp_med    1\n",
       "imp_mv     1\n",
       "Name: best_score_, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Groupby methods/steps and compare count and score min, max, mean.\n",
    "print('\\nImputation method stats:\\n')\n",
    "imp_gscvs_df.groupby(by='imp_method')['best_score_'].min().sort_values(ascending=False)\n",
    "imp_gscvs_df.groupby(by='imp_method')['best_score_'].mean().sort_values(ascending=False)\n",
    "imp_gscvs_df.groupby(by='imp_method')['best_score_'].max().sort_values(ascending=False)\n",
    "\n",
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head().groupby(by='imp_method')\\\n",
    "    ['best_score_'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>kn_clf__n_neighbors</th>\n",
       "      <th>kn_clf__weights</th>\n",
       "      <th>kn_clf__algorithm</th>\n",
       "      <th>kn_clf__leaf_size</th>\n",
       "      <th>kn_clf__n_jobs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_method</th>\n",
       "      <th>selector</th>\n",
       "      <th>decomp</th>\n",
       "      <th>classifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>imp_mv</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imp_med</th>\n",
       "      <th>sel_per</th>\n",
       "      <th>fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">imp0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">sel_per</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">fica</th>\n",
       "      <th>rf_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_clf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kn_clf</th>\n",
       "      <td>3.0</td>\n",
       "      <td>uniform</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       kn_clf__n_neighbors kn_clf__weights  \\\n",
       "imp_method selector decomp classifier                                        \n",
       "imp_mv     sel_per  fica   rf_clf                      NaN             NaN   \n",
       "imp_med    sel_per  fica   rf_clf                      NaN             NaN   \n",
       "imp0       sel_per  fica   rf_clf                      NaN             NaN   \n",
       "                           ab_clf                      NaN             NaN   \n",
       "                           kn_clf                      3.0         uniform   \n",
       "\n",
       "                                      kn_clf__algorithm  kn_clf__leaf_size  \\\n",
       "imp_method selector decomp classifier                                        \n",
       "imp_mv     sel_per  fica   rf_clf                   NaN                NaN   \n",
       "imp_med    sel_per  fica   rf_clf                   NaN                NaN   \n",
       "imp0       sel_per  fica   rf_clf                   NaN                NaN   \n",
       "                           ab_clf                   NaN                NaN   \n",
       "                           kn_clf             ball_tree                8.0   \n",
       "\n",
       "                                       kn_clf__n_jobs  \n",
       "imp_method selector decomp classifier                  \n",
       "imp_mv     sel_per  fica   rf_clf                 NaN  \n",
       "imp_med    sel_per  fica   rf_clf                 NaN  \n",
       "imp0       sel_per  fica   rf_clf                 NaN  \n",
       "                           ab_clf                 NaN  \n",
       "                           kn_clf                -1.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_gscvs_df.sort_values(by='best_score_', ascending=False).head()\\\n",
    "    [classifiers['kn_clf']['params'].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
